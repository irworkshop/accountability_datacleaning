---
title: "Kentucky Lobbyists"
author: "Kiernan Nicholls"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
fs::dir_create(here::here("df", "data", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This package contains
functions custom made to help facilitate the processing of campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load(
  tidyverse, # data manipulation
  lubridate, # datetime strings
  textreadr, # read text files
  magrittr, # pipe opperators
  janitor, # dataframe clean
  refinr, # cluster and merge
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here}
# where does this document knit?
here::here()
```

# Registration

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Data

The data is obtained from the [Kentucky Legislative Ethics Commission (KLEC)][03]:

[03]: https://klec.ky.gov/Pages/default.aspx

> KLEC has jurisdiction over
> 
> * Legislative agents (lobbyists),
> * Employers (individuals or entities who engage legislative agents), and
> * Members of the General Assembly.
> 
> The legislative ethics law covers four broad subject matters
> 
> * Registration of legislative agents and employers;
> * Statements by legislative agents and employers of:
>     * lobbying expenditures and expenses, and financial transactions;
> * Conduct of members of the General Assembly; and
> * Financial disclosure statements of the General Assembly, legislative candidates, and
> * key legislative staff.

The KLEC provides [a rich text file (RTF)][04] containing a list of legislative agents (lobbyists).

[04]: https://klec.ky.gov/Reports/Reports/Agents.rtf

## Import

The text file is a table of lobbyists with their clients indented below them.  With the `textreadr`
package, we can read the RTF file into a character vector of the lines on the document.

```{r raw_read}
lob_url <- "https://klec.ky.gov/Reports/Reports/Agents.rtf"
kylr <- read_rtf(file = lob_url)
```

```{r raw_head, echo=FALSE}
head(kylr)
```

First, we need to remove the header and footer from each page and keep only those lines which
contain the lobbyist name table information.

```{r raw_trim}
kylr <- str_subset(kylr, "Kentucky Registered Legislative Agents", negate = TRUE)
kylr <- str_subset(kylr, "\\w+\\s\\d{1,2},\\s\\d{4}", negate = TRUE)
kylr <- str_subset(kylr, "Legislative Agents/Employer\tPhone\tContact\tAddress", negate = TRUE)
kylr <- str_subset(kylr, "\\d{1,2}/\\d{1,2}/\\d{4}\t\\d{2}", negate = TRUE)
kylr <- str_replace_all(kylr, "\"", "\'")
```

## Wrangle

We need to `tibble::enframe()` the character vector and turn it into a single column data frame.
From there, we can `tidyr::separate()` the column into it's four component elements.

```{r raw_sep}
kylr <- kylr %>%
  enframe(name = "line", value = "text") %>%
  separate(
    col = text,
    into = c("name", "phone", "contact", "address"),
    sep = "\t"
  )
```

```{r echo=FALSE}
head(kylr)
```

Then, we have to use the indentation of the text file to identify which rows belong to lobbyist
information and which belong to their principal clients.

```{r raw_indent}
indent <- which(is.na(kylr$address))
kylr <- mutate(kylr, address = coalesce(address, contact))
kylr$contact[indent] <- NA
```

Using this identation, we can shift the lobbyist names over into a _new_ column and `dplyr::fill()`
that name and address down _alongside_ each of their clients below. Then this new data frame
is re-arranged into a table with each record identifying a lobbyist and a single client. In this
sense, the lobbyist names are now repeated for each client.

```{r raw_shift}
kylr <- kylr %>%
  mutate(
    lob_name = if_else(
      condition = is.na(contact),
      true = name,
      false = NA_character_
    ),
    lob_phone = if_else(
      condition = is.na(contact),
      true = phone,
      false = NA_character_
    ),
    lob_address = if_else(
      condition = is.na(contact),
      true = address,
      false = NA_character_
    )
  ) %>%
  fill(starts_with("lob")) %>%
  mutate_if(is_character, str_trim) %>%
  mutate_all(str_to_upper) %>% 
  filter(!is.na(contact)) %>%
  rename(
    pri_name = name,
    pri_phone = phone,
    pri_contact = contact,
    pri_address = address
  ) %>%
  select(
    starts_with("lob"),
    starts_with("pri")
  )
```

Now, we need to `tidyr::separate()` the two new `*_address` columns into the other components.
First, we will split the lobbyist's address into the street, city, state, and ZIP code. We will

```{r raw_sep_lob}
kylr <- kylr %>%
  separate(
    col = lob_address,
    into = c(glue("lob_addr{1:10}"), "lob_extra"),
    sep = ",\\s",
    fill = "left",
    extra = "merge"
  ) %>%
  na_if("") %>%
  unite(
    starts_with("lob_addr"),
    col = "lob_addr",
    na.rm = TRUE,
    sep = " ",
  ) %>% 
  separate(
    col = lob_extra,
    into = c("lob_extra", "lob_zip"),
    sep = "\\s(?=\\d)",
    fill = "left",
    extra = "merge"
  ) %>% 
  separate(
    col = lob_extra,
    into = c("lob_city", "lob_state"),
    sep = "\\s(?=[^ ]*$)",
    fill = "left",
    extra = "merge"
  )
```

Then, we will perform the same process for the associated principal clients.

```{r raw_sep_pri}
kylr <- kylr %>%
  separate(
    col = pri_address,
    into = c(glue("pri_addr{1:10}"), "pri_extra"),
    sep = ",\\s",
    fill = "left",
    extra = "merge"
  ) %>%
  na_if("") %>%
  unite(
    starts_with("pri_addr"),
    col = "pri_addr",
    na.rm = TRUE,
    sep = " ",
  ) %>% 
  separate(
    col = pri_extra,
    into = c("pri_extra", "pri_zip"),
    sep = "\\s(?=\\d)",
    fill = "left",
    extra = "merge"
  ) %>% 
  separate(
    col = pri_extra,
    into = c("pri_city", "pri_state"),
    sep = "\\s(?=[^ ]*$)",
    fill = "left",
    extra = "merge"
  )
```

We can also split the lobbyist name to improve searchability.

```{r raw_sep_name}
kylr <- kylr %>% 
  separate(
    col = lob_name,
    into = c("lob_last", "lob_first"),
    sep = ",\\s",
    extra = "merge" 
  )
```

Through this wrangling, we can see how we were able to reshape a single column text file into
a clear tidy data frame of lobbyist/client relationships. Each record now identifies both parties
in a lobbyist relationship, with information split into separate columns for searchability.

```{r echo=FALSE}
head(kylr)
```

## Normal

Now that the text file has been wrangled into a database format, we can proceed to manipulate the
_content_ of the file to improve the searchability of the database.

### Phone

We can convert all telephone numbers to a single format with `campfin::normal_phone()`.

```{r phone_norm}
kylr <- mutate_at(
  .tbl  = kylr,
  .vars = vars(ends_with("phone")),
  .funs = list(norm = normal_phone)
)
```

```{r phone_view, echo=FALSE}
kylr %>% 
  select(starts_with("lob_phone")) %>%
  distinct() %>% 
  sample_frac()
```

### Address

For street addresses, we can use `campfin::normal_address()` to force string consistency and expand
abbreviations.

```{r addr_norm}
kylr <- mutate_at(
  .tbl  = kylr,
  .vars = vars(ends_with("addr")),
  .funs = list(norm = normal_address),
  abbs  = usps_street
)
```

```{r addr_view, echo=FALSE}
kylr %>% 
  select(starts_with("lob_addr")) %>%
  distinct() %>% 
  sample_frac()
```

### ZIP

Only the 5-digit ZIP codes are desired. The `campfin::normal_zip()` function trims and pads ZIP 
codes to make them valid.

```{r zip_norm}
kylr <- mutate_at(
  .tbl  = kylr,
  .vars = vars(ends_with("zip")),
  .funs = list(norm = normal_zip)
)
```

```{r zip_progress, echo=FALSE}
progress_table(
  kylr$lob_zip,
  kylr$lob_zip_norm,
  kylr$pri_zip,
  kylr$pri_zip_norm,
  compare = valid_zip
)
```

## State

The state variables are already entirely normalized to their 2-digit USPS abbreviations.

```{r state}
count(kylr, lob_state, sort = TRUE)
prop_in(kylr$lob_state, valid_state)
# USPS store, manually checked
kylr$pri_state <- str_replace(kylr$pri_state, "RD", "KY")
prop_in(kylr$pri_state, valid_state)
```

### City

City strings are the most troublesome due to the sheer variety in names and the multiple valid
ways to list the same cities. Using `campfin::normal_city()` is the first step in improving the
consistency.

```{r city_norm}
kylr <- mutate_at(
  .tbl  = kylr,
  .vars = vars(ends_with("city")),
  .funs = list(norm = normal_city),
  abbs  = usps_city
)
```

Then, we compare the normalized city string to the _expected_ city for that record's state and ZIP
code. If the two are _extremelly_ similar, we can confidently use the correct, expected value.

```{r city_swap_lob}
kylr <- kylr %>% 
  left_join(
    y = zipcodes,
    by = c(
      "lob_state" = "state",
      "lob_zip_norm" = "zip"
    )
  ) %>% 
  rename(city_match = city) %>% 
  mutate(
    match_abb = is_abbrev(lob_city_norm, city_match),
    match_dist = str_dist(lob_city_norm, city_match),
    lob_city_swap = if_else(
      condition = match_abb | match_dist == 1,
      true = city_match,
      false = lob_city_norm
    )
  ) %>% 
  select(
    -city_match,
    -match_dist,
    -match_abb
  )
```

Then simply repeat that checking for the principal city.

```{r city_swap_pri}
kylr <- kylr %>% 
  left_join(
    y = zipcodes,
    by = c(
      "pri_state" = "state",
      "pri_zip_norm" = "zip"
    )
  ) %>% 
  rename(city_match = city) %>% 
  mutate(
    match_abb = is_abbrev(pri_city_norm, city_match),
    match_dist = str_dist(pri_city_norm, city_match),
    pri_city_swap = if_else(
      condition = match_abb | match_dist == 1,
      true = city_match,
      false = pri_city_norm
    )
  ) %>% 
  select(
    -city_match,
    -match_dist,
    -match_abb
  )
```

These two-step process is able to bring both city variables to near complete normality.

```{r city_progress, echo=FALSE}
progress_table(
  kylr$lob_city,
  kylr$lob_city_norm,
  kylr$lob_city_swap,
  compare = c(valid_city, extra_city)
)
progress_table(
  kylr$pri_city,
  kylr$pri_city_norm,
  kylr$pri_city_swap,
  compare = c(valid_city, extra_city)
)
```

## Export

```{r proc_glimpse}
glimpse(kylr)
```

We can now export this wrangled and normalized data set.

```{r proc_dir}
proc_dir <- here("ky", "lobbying", "data", "processed")
dir_create(proc_dir)
```

```{r proc_write}
kylr <- kylr %>% 
  # swap over norm
  select(-ends_with("city_norm")) %>%
  rename(
    lob_city_norm = lob_city_swap,
    pri_city_norm = pri_city_swap
  )

write_csv(
  x = kylr,
  path = glue("{proc_dir}/ky_lobby_reg.csv"),
  na = ""
)
```

# Compensation

We can also download lobbyist compensation data for the past two years. These files can be read
by reading the lines of each, manipulating them slightly, and passing them back into 
`readr::read_delim()`.

```{r comp_read}
# read lines from both years
kylc_lines <- map(
  .f = read_lines,
  .x = c(
    "https://klec.ky.gov/Reports/Reports/LAComp.txt",
    "https://klec.ky.gov/Reports/Reports/LACompPrior.txt"
  )
)

kylc_lines <- as_vector(kylc_lines)
# remove headers
kylc_lines <- str_subset(kylc_lines, "^Legislative\\sAgent\\sCompensation$", negate = TRUE)
kylc_lines <- str_subset(kylc_lines, "^\\w+\\s\\d{1,2},\\s\\d{4}$", negate = TRUE)
# remove repeated col headers
kylc_names <- kylc_lines[[1]]
kylc_lines <- str_subset(kylc_lines, kylc_names, negate = TRUE)
kylc_names <- make_clean_names(str_split(kylc_names, ";", simplify = TRUE))
kylc_names <- c("lob_name", "report_period", "pri_name", "compensation")
# identify overflow lines
overflow <- which(str_count(kylc_lines, ";") < 3)
# collapse with previous line
kylc_lines[overflow - 1] <- str_replace(
  string = kylc_lines[overflow - 1], 
  pattern = "(\\s)(?=;\\$)", 
  replacement = glue("\\1{kylc_lines[overflow]}")
)
# remove overflow lines
kylc_lines <- kylc_lines[-overflow]

# reas as tabular 
kylc <- 
  read_delim(
    file = kylc_lines,
    delim = ";",
    escape_double = FALSE,
    escape_backslash = FALSE,
    col_names = kylc_names,
    col_types = cols(
      .default = col_character(),
      compensation = col_number()
    )
  ) %>%
  # split start and end dates
  separate(
    col = report_period,
    into = c("start_date", "end_date"),
    sep = "\\s"
  ) %>% 
  # convert both to date cols
  mutate_at(
    .vars = vars(ends_with("date")),
    .funs = lubridate::mdy
  ) %>% 
  mutate_if(
    .predicate = is_character,
    .funs = str_normal,
    punct = FALSE
  ) %>% 
  separate(
    col = lob_name,
    into = c("lob_last", "lob_first"),
    sep = "\\s",
    extra = "merge" 
  )
```

```{r comp_glimpse}
head(kylc)
tail(kylc)
glimpse(sample_frac(kylc))
```

Since this database will be uploaded separately from the lobbyist registration containing the
phone number and addresses of lobbyists and principal clients, we will have to add these columns
so that the compensation records will show up when this information is searched.

```{r comp_join}
lob_info <- kylr %>% 
  select(starts_with("lob_")) %>% 
  select(lob_first, lob_last, ends_with("_norm"))

pri_info <- kylr %>% 
  select(starts_with("pri_")) %>% 
  select(pri_name, ends_with("_norm"))

kylc <- kylc %>% 
  left_join(lob_info, by = c("lob_last", "lob_first")) %>% 
  left_join(pri_info, by = "pri_name")
```

We can see that most of these new columns were joined successfully.

```{r comp_na}
col_stats(kylc, count_na)
```

```{r comp_glimpse_new}
glimpse(sample_frac(kylc))
```

This compensation database can also be written to disk.

```{r comp_write}
write_csv(
  x = kylc,
  path = glue("{proc_dir}/ky_lobby_comp.csv"),
  na = ""
)
```

