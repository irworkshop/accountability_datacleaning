---
title: "{State} {Data}"
author: "{First} {Last}"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = FALSE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  stringdist, # levenshtein value
  tidyverse, # data manipulation
  lubridate, # datetime strings
  magrittr, # pipe opperators
  janitor, # dataframe clean
  zipcode, # clean & database
  readxl, # read excel file
  knitr, # knit documents
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

The IRW's `campfin` package will also have to be installed from GitHub. This package contains
functions custom made to help facilitate the processing of campaign finance data.

```{r load_campfin}
pacman::p_load_current_gh("kiernann/campfin")
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here, collapse=TRUE}
# where dfs this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Data

### Download

```{r make_urls}
cand_urls <- c(
  "https://sos.idaho.gov/elect/finance/2008/candexp.xls",
  "https://sos.idaho.gov/elect/finance/2010/candexp.xls",
  "https://sos.idaho.gov/elect/finance/2012/2012_cand_exp.xlsx",
  "https://sos.idaho.gov/elect/finance/2014/2014_cand_exp.xlsx",
  "https://sos.idaho.gov/elect/finance/2016/2016_cand_expend.xlsx",
  "https://sos.idaho.gov/elect/finance/2018/candidate_expenditures.xlsx"
)

comm_urls <- c(
  "https://sos.idaho.gov/elect/finance/2008/commexp.xls",
  "https://sos.idaho.gov/elect/finance/2010/commexp.xls",
  "https://sos.idaho.gov/elect/finance/2012/2012_comm_exp.xlsx",
  "https://sos.idaho.gov/elect/finance/2014/2014_comm_exp.xlsx",
  "https://sos.idaho.gov/elect/finance/2016/2016_comm_expend.xlsx",
  "https://sos.idaho.gov/elect/finance/2018/committee_expenditures.xlsx"
)
```

```{r download_cand}
cand_dir <- here("id", "expends", "data", "raw", "cand")
dir_create(cand_dir)
if (!all_files_new(cand_dir)) {
  for (year_url in cand_urls) {
    year <- str_extract(year_url, "\\d+")
    download.file(
      url = year_url,
      destfile = glue("{cand_dir}/{year}_{basename(year_url)}")
    )
  }
}
```

```{r download_comm}
dir_create(comm_dir)
comm_dir <- here("id", "expends", "data", "raw", "comm")
if (!all_files_new(comm_dir)) {
  for (year_url in comm_urls) {
    year <- str_extract(year_url, "\\d+")
    download.file(
      url = year_url,
      destfile = glue("{comm_dir}/{year}_{basename(year_url)}")
    )
  }
}
```

## Read


