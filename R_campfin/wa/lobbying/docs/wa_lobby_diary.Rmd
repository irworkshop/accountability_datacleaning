---
title: "State Data"
author: "First Last"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  # it's nice to un-collapse df print
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This package contains
functions custom made to help facilitate the processing of campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irwokshop/campfin")
pacman::p_load(
  stringdist, # levenshtein value
  RSelenium, # remote browser
  tidyverse, # data manipulation
  lubridate, # datetime strings
  magrittr, # pipe opperators
  janitor, # dataframe clean
  refinr, # cluster and merge
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here, collapse=TRUE}
# where dfs this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Registration

Data is obtained from the [Washington Public Disclosure Commission][wpdc] (PDC). The dataset is
found on the [Washington state OpenData portal][wod]. 

Each observation represents the relationship between a lobbying agent, their employer, and the
firm for which they lobby. Each lobbyist can have multiple records, each with another client
or employer.

> This dataset contains information about the agents employed by a lobbying firm and the employers
they ultimately lobby for.
>
> See the Lobbyist Agent Employers dataset for each individual lobbyist agent to employer
relationship.
>
> A lobbyist/firm registers with the PDC, not individual agents (employees) of that firm. The PDC
provides this data as a way to see the individuals that lobby for a firm and all the employers of
that firm. This does not indicate that a particular agent necessarily lobbied for a particular
employer, merely that the agent's firm lobbied for that employer.
>
> This dataset is a best-effort by the PDC to provide a complete set of records as described
herewith and may contain incomplete or incorrect information. The PDC provides access to the
original reports for the purpose of record verification.

[wpdc]: https://www.pdc.wa.gov/
[wod]: https://data.wa.gov

* `id`: An auto-generated unique identifier representing a relationship between a Lobbyist firm, an
Agent, and an Employer for a given year.
* `filer_id`: The unique id assigned to the lobbyist/firm that employs this agent.
* `lobbyist_firm_name`: The lobbyist firm who employs the agent.
* `lobbyist_phone`: The phone number associated with the lobbyist firm.
* `lobbyist_email`: The email address associated with this lobbyist firm.
* `lobbyist_address`: The address of the lobbyist firm.
* `employers`: The list of all employers that this agent's firm lobbied for in the given year.
* `agent_name`: The registered name of the agent.
* `agent_bio`: The biographical data submitted by the agent.
* `agent_pic_url`: A link to the agents picture.
* `employment_year`: The year the agent lobbied for this employer
* `lobbyist_firm_url`: A link to the registration information submitted by the lobbyist.

https://data.wa.gov/Politics/Lobbyist-Agents/bp5b-jrti

### Import

We can import the file directly from the OpenData portal using `readr::read_csv()`.

```{r read_raw}
walr <- read_csv(
  file = "https://data.wa.gov/api/views/bp5b-jrti/rows.csv",
  col_types = cols(
    .default = col_character(),
    employment_year = col_integer()
  )
)
```

### Explore

#### Missing

Only the `agent_bio` variable is missing any values.

```{r glimpse_missing}
col_stats(walr, count_na)
```

```{r flag_na}
walr <- flag_na(walr, -agent_bio)
sum(walr$na_flag)
walr <- select(walr, -na_flag)
```

#### Duplicate

There are no duplicate records

```{r flag_dupes}
walr <- flag_dupes(walr, -id)
sum(walr$dupe_flag)
walr <- select(walr, -dupe_flag)
```

#### Categorical

```{r glimpse_distinct}
col_stats(walr, n_distinct)
```

#### Continuous

```{r count_year}
count(walr, employment_year)
```

```{r year_bar, echo=FALSE}
walr %>% 
  count(employment_year) %>% 
  ggplot(aes(x = employment_year, y = n)) +
  geom_col(fill = RColorBrewer::brewer.pal(3, "Dark2")[1]) +
  labs(
    title = "Washington Lobbyists Relationships",
    caption = "Source: Washington Public Disclosure Commission",
    x = "Employment Year",
    y = "Lobbist Registrants"
  )
```

### Wrangle

```{r case_change}
walr <- mutate_at(walr, vars(3, 6, 7, 8), str_to_upper)
walr <- mutate_at(walr, vars(lobbyist_email), str_to_lower)
```

#### Telephone

```{r normal_phone}
walr <- walr %>% 
  mutate(
    phone_norm = normal_phone(
      number = lobbyist_phone,
      format = "(%a) %e-%l",
      na_bad = FALSE,
      convert = TRUE, 
      rm_ext = FALSE
    )
  )
```

```{r view_phone_post, echo=FALSE}
walr %>% 
  select(lobbyist_phone, phone_norm) %>% 
  sample_frac()
```

#### Separate Address

Using regular expression and our `zipcodes` database, we can extract the ZIP code, state
abbreviation, and city name from the end of the `lobbyist_address` variable.

```{r extract_state_zip}
walr <- walr %>% 
  mutate(
    zip_sep = str_extract(lobbyist_address, "\\d+(?:-\\d{4})?$"),
    state_sep = str_extract(lobbyist_address, "[:alpha:]+(?=\\s+\\d+(?:-\\d{4})?$)"),
    other_sep = lobbyist_address %>%
      str_remove("[:alpha:]+(?=\\s+\\d+(?:-\\d{4})?$)") %>% 
      str_remove("\\d+(?:-\\d{4})?$") %>% 
      str_trim("right"),
    city_sep = NA_character_
  )
```

To extact the cities from the end of this string, we'll have to expand our `zipcodes` database
with other common city names.

```{r increase_zips}
zips2 <- zipcodes %>% 
  add_row(city = "DES MOINES", state = "WA") %>% 
  add_row(city = "TUKWILA", state = "WA") %>% 
  add_row(city = "SEATAC", state = "WA") %>% 
  add_row(city = "TIGARD", state = "OR") %>% 
  add_row(city = "MILL CREEK", state = "WA") %>%
  add_row(city = "BRIDGEVIEW COURT", state = "IN") %>% 
  add_row(city = "LAKE TAPPS", state = "WA") %>% 
  add_row(city = "LAKE FOREST PARK", state = "WA") %>% 
  add_row(city = "GOLD RIVER", state = "CA") %>% 
  add_row(city = "SEATAC", state = "WA")
```

Then, for each row, we attempt to extract every city name (for that row's state) from the end of
the address string sans ZIP code and state.

```{r city_loop_extract}
for (row in seq_along(walr$other_sep)) {
  state <- walr$state_sep[row]
  for (city in unique(zips2$city[zips2$state == state])) {
    walr$city_sep[row] <- str_extract(
      string = walr$other_sep[row],
      pattern = glue("\\b{city}\\b")
    )
    if(!is.na(walr$city_sep[row])) break
  }
}
```

For those rows where a state was not extracted, we can simply take the last word from the string.

```{r last_word_city}
walr$city_sep[which(is.na(walr$city_sep))] <- word(walr$other_sep[which(is.na(walr$city_sep))], -1)
```

Then, we can remove this `city_sep` from the `other_sep` vector to leave only the street address.

```{r extract_address}
walr <- walr %>% 
  mutate(
    address_sep = other_sep %>% 
      str_remove(city_sep) %>% 
      str_trim("right")
  )
```

```{r view_address_split, echo=FALSE}
walr %>% 
  select(lobbyist_address, address_sep, city_sep, state_sep, zip_sep) %>% 
  distinct() %>% 
  sample_frac()
```

#### Normalize Address

We can normalize the address with `campfin::normal_address()` to reduce inconsistencies and expand
USPS abbreviations.

```{r normal_address}
walr <- walr %>% 
  mutate(
    address_norm = normal_address(
        address = address_sep,
        abbs = usps_street,
        na_rep = TRUE
      )
  )
```

```{r view_address_norm, echo=FALSE}
walr %>% 
  select(starts_with("address")) %>% 
  distinct() %>% 
  sample_frac()
```

#### Normalize ZIP

We can create normalize, valid 5-digit ZIP codes using `campfin::normal_zip()`.

```{r normal_zip}
walr <- walr %>% 
  mutate(
    zip_norm = normal_zip(
      zip = zip_sep,
      na_rep = TRUE
    )
  )
```

```{r zip_progress}
progress_table(
  walr$zip_sep,
  walr$zip_norm,
  compare = valid_zip
)
```

#### Normalize State

The `state_sep` variable is `r percent(prop_in(walr$state_sep, valid_state))` valid.

```{r}
prop_in(walr$state_sep, valid_state)
```

#### Normal City

```{r normal_city}
walr <- walr %>% 
  mutate(
    city_norm = normal_city(
      city = city_sep,
      abbs = usps_city,
      na = invalid_city
    )
  ) %>% 
  left_join(
    y = zipcodes,
    by = c(
      "state_sep" = "state",
      "zip_norm" = "zip"
    )
  ) %>% 
  rename(city_match = city) %>% 
  mutate(
    match_dist = str_dist(city_norm, city_match),
    match_abb = is_abbrev(city_norm, city_match),
    city_swap = if_else(
      condition = match_abb | match_dist == 1,
      true = city_match,
      false = city_norm
    )
  )
```

```{r city_progress}
progress_table(
  walr$city_sep,
  walr$city_norm,
  walr$city_swap,
  compare = valid_city
)
```

```{r}
walr %>% 
  filter(city_swap %out% valid_city) %>% 
  count(city_swap, sort = TRUE)
```

### Export

```{r create_proc_dir}
proc_dir <- here("wa", "lobbying", "data", "processed")
dir_create(proc_dir)
```

```{r write_clean}
walr <- walr %>% 
  select(
    -zip_sep,
    -other_sep,
    -city_sep,
    -city_norm,
    -address_sep,
    -city_match,
    -match_dist,
    -match_abb
  ) %>% 
  rename(
    address_clean = address_norm,
    city_clean = city_swap,
    state_clean = state_sep,
    zip_clean = zip_norm,
    phone_clean = phone_norm
  )
 
write_csv(
  x = walr,
  path = glue("{proc_dir}/wa_lobbyist_clean.csv"),
  na = ""
)
```

## Compensation

The PDC also provdies a second data set titled ["Lobbyist Compensation and Expenses by Source"][ce] 
which can be found on the same portal.

[ce]: https://data.wa.gov/Politics/Lobbyist-Compensation-and-Expenses-by-Source/9nnw-c693

> This dataset contains compensation and expense summary records from the monthly reports of
lobbying activity. One record is included for each client that paid compensation or incurred
expenses during the filing period. If the lobbyist firm themselves incurred any expenses not
reimbursed by a client, a record is included summarizing the lobbyist firm's expenses. If a
lobbyist reported no compensation or expenses on the report, no records will be in this dataset.
Records are included for a period of ten years, beginning in January, 2016.

The data does have a condition of release, which this project meets:

> CONDITION OF RELEASE: This publication and or referenced documents constitutes a list of
individuals prepared by the Washington State Public Disclosure Commission and may not be used for
commercial purposes. This list is provided on the condition and with the understanding that the
persons receiving it agree to this statutorily imposed limitation on its use. See RCW 42.56.070(9)
and AGO 1975 No. 15.

There are 28 variables in the table:

* `id`: This is the unique identifier for this **dataset.**
* `report_number`: This is the identifying number of the filed L2...
* `origin`: This value shows **how** the report was filed: FE = electronically; FP = Paper.
* `filer_id`: This is the unique lobbyist id for this **lobbyist**
* `filer_name`: This is the title of the lobbyist or lobbyist firm, as reported when filing..
* `type`: Shows if this report was filed for an employer or for a lobbyist.
* `funding_source_id`: This is the unique identifier of the Firm/Emp relationship record...
* `funding_source_name`: This is the title of the Firm/Employer relationship for this L2.
* `filing_period`: The filing period for this report.
* `receipt_date`: The date that the report was filed.
* `employer_id`: This is the unique employer id for this employer...
* `employer_name`: This is the title of the employer as reported when filing...
* `compensation`: This is the sum total of compensation reported for this employer...
* `sub_lobbyist_compensation`: Payments to other lobbyists hired by the lobbyist or paid by the lobbyist from a portion of the funds received from the employer.
* `net_compensation`: The compensation the lobbyist received after paying any subcontracted lobbyists.
* `personal_expenses`: This is the sum total of personal expenses...
* `entertainment`: This is the sum total of entertainment expenses...
* `contributions`: This is the sum total of contributions reported...
* `advertising`: This is the sum total of advertising expenses...
* `political_ads`: This is the sum total of political ads expenses...
* `other`: This is the sum total of other expenses...
* `total_expenses`: This column is a total of all "expenses" incurred by the lobbyist for all employers for a given year...
* `net_total`: This column is the total of all expenses and compensation, minus sub lobbyist compensation.
* `employment_registration_id`: The ID of the record that identifies the employment of the lobbyist by their client and any subcontractor.
* `employment_type`: Signifies a direct or subcontracted employment relationship.
* `contractor_id`: This is the unique identifier corresponding to contractor records in the dataset.
* `contractor_name`: This is the contractor name...
* `url`: A permanent link to a .pdf copy of the original filed report.

https://data.wa.gov/Politics/Lobbyist-Agents/bp5b-jrti

### Import

We can import the file directly from the OpenData portal using `readr::read_csv()`.

```{r read_raw}
walc <- read_csv(
  file = "https://data.wa.gov/api/views/9nnw-c693/rows.csv",
  col_types = cols(
    .default = col_character(),
    # filing_period =  col_date("%m/%d/%Y %H:%M:%S %p"),
    # receipt_date = col_date("%m/%d/%Y %H:%M:%S %p"),
    compensation = col_number(),
    sub_lobbyist_compensation = col_number(),
    net_compensation = col_number(),
    personal_expenses = col_number(),
    entertainment = col_number(),
    contributions = col_number(),
    advertising = col_number(),
    political_ads = col_number(),
    other = col_number(),
    total_expenses = col_number(),
    net_total = col_number()
  )
)
```

The dates are a mix of those containing midnight and those without. For the two date columns, we
can trim off the time and parse as a date column.

```{r parse_dates}
walc <- walc %>% 
  mutate_at(
    .vars = vars(filing_period, receipt_date),
    .funs = ~mdy(str_sub(., end = 10))
  )
```

Since this database will be uploaded separately from the lobbyist registration containing the
phone number and addresses of lobbyists, we will have to add these columns
so that the expenditure records will show up when this information is searched.

```{r ex_join}
lob_info <- distinct(select(walr, filer_id, ends_with("clean")))
walc <- left_join(walc, lob_info, by = "filer_id")
```

### Explore

```{r ex_glimpse}
head(walc)
tail(walc)
glimpse(sample_frac(walc))
```

#### Missing

Very few records are missing the key variables needed to properly identify a compensation record.

```{r ex_glimpse_missing}
col_stats(walc, count_na)
```

#### Duplicate

There are no duplicate records

```{r ex_flag_dupes}
walc <- flag_dupes(walc, -id)
```

#### Categorical

```{r ex_glimpse_distinct}
col_stats(walc, n_distinct)
```

#### Continuous

The number of lobbyists submitting reports remains relatively constant for the last 4 years.

```{r ex_year_bar, echo=FALSE}
walc %>% 
  filter(
    year(filing_period) > 1970,
    filing_period < today()
  ) %>% 
  count(filing_period) %>% 
  ggplot(aes(x = filing_period, y = n)) +
  geom_col(fill = RColorBrewer::brewer.pal(3, "Dark2")[1]) +
  labs(
    title = "Washington Lobbyists L2 Filings per Period",
    caption = "Source: Washington Public Disclosure Commission",
    x = "Filing Period (Month)",
    y = "Unique Reports"
  )
```

### Export

```{r create_proc_dir}
proc_dir <- here("wa", "lobbying", "data", "processed")
dir_create(proc_dir)
```

```{r write_clean}
walr %>% 
  select(
    -zip_sep,
    -other_sep,
    -city_sep,
    -city_norm,
    -address_sep,
    -city_match,
    -match_dist,
    -match_abb
  ) %>% 
  rename(
    address_clean = address_norm,
    city_clean = city_swap,
    state_clean = state_sep,
    zip_clean = zip_norm,
    phone_clean = phone_norm
  ) %>% 
  write_csv(
    path = glue("{proc_dir}/wa_lobbyist_clean.csv"),
    na = ""
  )
```
