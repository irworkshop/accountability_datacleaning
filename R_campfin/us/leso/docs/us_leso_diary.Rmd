---
title: "United States Law Enforcement 1033 Transfers"
author: "Kiernan Nicholls"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
if (!interactive()) {
  options(width = 99)
  set.seed(5)
}
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
doc_dir <- fs::dir_create(here::here("us", "leso", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give
journalists, policy professionals, activists, and the public at large a simple
way to search across huge volumes of public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each
dataset row as a transaction. For each transaction there should be (at least) 3
variables:

1. All **parties** to a transaction.
2. The **date** of the transaction.
3. The **amount** of money involved.

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for entirely duplicated records.
1. Check ranges of continuous variables.
1. Is there anything blank or missing?
1. Check for consistency issues.
1. Create a five-digit ZIP Code called `zip`.
1. Create a `year` field from the transaction date.
1. Make sure there is data on both parties to a transaction.

## Packages

The following packages are needed to collect, manipulate, visualize, analyze,
and communicate these results. The `pacman` package will facilitate their
installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This
package contains functions custom made to help facilitate the processing of
campaign finance data.

```{r load_packages, message=FALSE, warning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load(
  tidyverse, # data manipulation
  lubridate, # datetime strings
  gluedown, # printing markdown
  magrittr, # pipe operators
  janitor, # clean data frames
  refinr, # cluster and merge
  readxl, # read excel files
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  rvest, # html scraping
  usmap, # plot us maps
  glue, # combine strings
  here, # relative paths
  httr, # http requests
  fs # local storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a
sub-directory of the more general, language-agnostic
[`irworkshop/accountability_datacleaning`][tap] GitHub repository.

The `R_campfin` project uses the [RStudio projects][rproj] feature and should be
run as such. The project also uses the dynamic `here::here()` tool for file
paths relative to _your_ machine.

```{r where_here}
# where does this document knit?
here::here()
```

[tap]: https://github.com/irworkshop/accountability_datacleaning
[rproj]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects

## Data

Per [Wikipedia](https://en.wikipedia.org/wiki/1033_program):

> In the United States, the 1033 Program transfers excess military equipment to
civilian law enforcement agencies. The program legally requires the Department
of Defense to make various items of equipment available to local law
enforcement. The 1033 program was instituted per Bill Clinton's 1997 National
Defense Authorization Act, though precedents to it existed following World War
II.

The Defense Logistics Agency (DLA) [electronic reading room][efoia] contains
electronic versions of the hard copy documents with data regarding 1033
transfers.

[efoia]: https://www.dla.mil/DispositionServices/FOIA/EFOIALibrary/

> DLA’s Law Enforcement Support Office transfers excess Department of Defense
property to federal, state, and local law enforcement agencies within the United
States and its Territories

There are two files pertaining to the 1033 program:

1. [LESO Property Transferred to Participating Agencies][leso1]
    * By state and agency name as of June 30, 2018. This is the most recent
    quarterly update of the accountable property held by participating agencies:
2. [LESO Information for Shipments and Cancellations of Property][leso2]
    * The information includes all requests made during the time period of April
    1 - June 30, 2018.

[leso1]: https://www.dla.mil/Portals/104/Documents/DispositionServices/LESO/DISP_AllStatesAndTerritories_06302018.xlsx
[leso2]: https://www.dla.mil/Portals/104/Documents/DispositionServices/LESO/DISP_Shipments_Cancellations_04012018_06302018.xlsx

## Download

We will be downloading the first file for now.

```{r raw_dir}
raw_dir <- dir_create(here("us", "leso", "data", "raw"))
raw_url <- "https://www.dla.mil/Portals/104/Documents/DispositionServices/LESO/"
raw_name <- "DISP_AllStatesAndTerritories_03312020.xlsx"
raw_url <- str_c(raw_url, raw_name)
raw_path <- path(raw_dir, raw_name)
```

```{r raw_download}
if (!file_exists(raw_path)) {
  download.file(raw_url, raw_path)
}
```

## Read

The Excel spreadsheet lists transfers to police departments to each state in
separate states. We can combine `purrr::map_df()` and `readxl::read_excel()` to
read all the sheets into a single data frame of transfers.

```{r raw_read}
leso <- raw_path %>%
  readxl::excel_sheets() %>%
  purrr::set_names() %>%
  purrr::map_df(
    .f = read_excel,
    .name_repair = make_clean_names,
    path = raw_path
  )
```

```{r raw_rename}
leso <- rename(
  .data = leso,
  to_station = station_name_lea,
  to_state = state,
  item = item_name,
  value = acquisition_value,
  date = ship_date
)
```

## Explore

```{r glimpse}
glimpse(leso)
tail(leso)
```

### Missing

Only one variable is missing any values. Nothing needs to be flagged.

```{r na_count}
col_stats(leso, count_na)
```

### Duplicates

There are quite a lot of duplicate records in the database. We can find and flag
these records with `campfin::flag_dupes()`.

```{r dupe_flag}
leso <- flag_dupes(leso, everything())
mean(leso$dupe_flag)
```

It looks like most of these duplicates are simply multiple items transferred in
the same shipment with a `quantity` of 1.

```{r dupe_view}
leso %>% 
  filter(dupe_flag) %>% 
  select(date, to_station, value, quantity, item) %>% 
  arrange(date)
```

```{r dupe_quantity}
leso %>% 
  filter(dupe_flag) %>% 
  count(quantity, sort = TRUE) %>% 
  add_prop()
```

We will remove the `dupe_flag` variable for any record with a `quantity` of 1.

```{r dupe_remove}
leso$dupe_flag[which(leso$quantity == 1)] <- FALSE
mean(leso$dupe_flag)
```

### Categorical

```{r distinct_count}
col_stats(leso, n_distinct)
```

```{r distinct_plots}
explore_plot(leso, demil_code)
explore_plot(leso, demil_ic)
```

### Amounts

```{r ammount_summary}
summary(leso$value)
mean(leso$value <= 0)
```

```{r hist_amount, echo=FALSE}
leso %>%
  filter(value >= 1) %>% 
  ggplot(aes(value)) +
  geom_histogram(fill = dark2["purple"], bins = 20) +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(
    breaks = c(1 %o% 10^(0:6)),
    labels = dollar,
    trans = "log10"
  ) +
  labs(
    title = "Military Equipment Transfer Values",
    caption = "Source: US DLA",
    x = "Amount",
    y = "Count"
  )
```

```{r amount_map, echo=FALSE}
per_cap <- leso %>% 
    rename(state = to_state) %>% 
    group_by(state, .drop = FALSE) %>% 
    summarise(sum = sum(value)) %>% 
    left_join(usa::states %>% select(name, abb), by = c("state" = "abb")) %>% 
    left_join(usa::facts %>% select(name, population)) %>% 
    mutate(val_per_cap = sum/population)
  plot_usmap(data = per_cap, values = "val_per_cap", color = "black") + 
    theme(legend.position = "right") +
    scale_fill_viridis_c(
      name = "Per Capita Value", 
      label = scales::dollar,
      direction = -1
    ) +
    labs(
      title = "1033 Transfer Values per Capita",
      subtitle = "All transfers since 1990 using 2010 population"
    )
```

### Dates

We can add the calendar year from `date` with `lubridate::year()`

```{r date_year}
leso <- mutate(leso, year = year(date))
```

```{r date_range}
min(leso$date)
sum(leso$year < 1990)
max(leso$date)
sum(leso$date > today())
```

```{r bar_year, echo=FALSE}
leso %>% 
  count(year) %>% 
  mutate(even = is_even(year)) %>% 
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = dark2["orange"]) + 
  scale_y_continuous(labels = comma) +
  scale_x_continuous(breaks = seq(1990, 2020, by = 2)) +
  coord_cartesian(xlim = c(1990, 2020)) +
  labs(
    title = "Military Equipment Transfers by Year",
    caption = "Source: US DLA",
    x = "Year Shipped",
    y = "Transfers"
  )
```

## Wrangle

The raw data does not include a variable indicating the source of each transfer,
but we know all transfers come from the United States Military. We can manually
add a new column so transfers can be searches.

```{r from_add}
leso <- mutate(
  .data = leso, 
  .before = 1,
  from_state = "US",
  from_dept = "Department of Defense"
)
```

## Conclude

1. There are `r comma(nrow(leso))` records in the database.
1. There are `r comma(sum(leso$dupe_flag))` duplicate records in the database.
1. The range and distribution of `amount` and `date` seem reasonable.
1. There are `r comma(sum(leso$na_flag))` records missing key variables.
1. There are no geographic variables other than the 2-letter state abbreviation.
1. The 4-digit `year` variable has been created with `lubridate::year()`.

## Export

Now the file can be saved on disk for upload to the Accountability server.

```{r clean_dir}
clean_dir <- dir_create(here("us", "leso", "data", "clean"))
clean_path <- path(clean_dir, "us_1033_transfers.csv")
write_csv(leso, clean_path, na = "")
file_size(clean_path)
mutate(file_encoding(clean_path), across(path, path.abbrev))
```

## Upload

Using the [duckr] R package, we can wrap around the [duck] command line tool to
upload the file to the IRW server.

[duckr]: https://github.com/kiernann/duckr
[duck]: https://duck.sh/

```{r clean_upload, eval=TRUE}
# remotes::install_github("kiernann/duckr")
s3_dir <- "s3:/publicaccountability/csv/"
s3_path <- path(s3_dir, basename(clean_path))
if (require(duckr)) {
  duckr::duck_upload(clean_path, s3_path)
}
```

## Dictionary

The following table describes the variables in our final exported file:

```{r dict_make, echo=FALSE}
dict_raw <- tibble(
  var = md_code(names(leso)),
  type = md_code(map_chr(leso, typeof)),
  def = c(
    "Manually added department \"styate\"",
    "Manually added department name",
    "Recieving station state",
    "Recieving station name",
    "Item's unique \"National Stock Number\"",
    "Item name",
    "Quantity of items transfered",
    "Units of item transfered",
    "Value of equipment transfered†",
    "Required level of destruction before transfer*",
    "Integrity Code*",
    "Date transfer was shipped",
    "Recieving station type (all \"State\")",
    "Flag indicating duplicate non-single transfer",
    "Calendar year shipped"
  )
)
```

```{r dict_md, echo=FALSE}
(dict_md <- kable(
  x = dict_raw,
  format = "markdown",
  col.names = c("Column", "Type", "Definition")
))
```

> †That figure can be misleading. The cost associated with the LESO/1033 Program
property is based on original acquisition value, i.e. what the procuring agency,
normally a branch of the military, paid for the item at the time it was
procured. Many of the items available in the excess property inventory were
procured decades ago, so the current value, with depreciation, would be
difficult (and not cost-effective) to determine. The original acquisition value
is the only cost component available in current data systems. Using the initial
acquisition value, the total amount transferred since the program’s inception in
1990 is $7.4 billion.

> *DEMIL code indicates the degree of required physical destruction, identifies
items requiring specialized capabilities or procedures, and identifies items
which do not require DEMIL but may require Trade Security Controls. It is used
throughout the life-cycle to identify control requirements required before
release from DoD control.  The DEMIL codes below are listed as the Highest
Severity to the Lowest Severity in DEMIL coding. DEMIL Integrity Code appear
adjacent to the DEMIL Code in FLIS that identify the validity of an item’s DEMIL
code. For additional information on DEMIL codes or DEMIL Integrity Codes, see
DOD 4160.28 DEMIL Program or DOD 4100.39M FLIS Manual.
