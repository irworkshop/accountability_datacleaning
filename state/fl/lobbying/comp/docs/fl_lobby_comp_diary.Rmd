---
title: "Florida Lobbyist Compensation"
author: "Kiernan Nicholls"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 3
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
fs::dir_create(here::here("fl", "lobbying", "comp", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This package contains
functions custom made to help facilitate the processing of campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load(
  tidyverse, # data manipulation
  lubridate, # datetime strings
  gluedown, # printing markdown
  magrittr, # pipe opperators
  janitor, # dataframe clean
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  rvest, # read web pages
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here, collapse=TRUE}
# where does this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Data

Data is obtained as tab-delinated files from the [Florida Lobbying Registration Office][lro] (LRO).

[lro]: https://floridalobbyist.gov/

### About

>  Delimited data files are made available below for compensation reports submitted online,
beginning in 2007. Data files for the last eight quarters will be retained for each branch. The
tab-delimited files below are in the (.TXT) format and can be imported into any word processor,
spreadsheet, or database program.

### Variables

The LRO provides a variable key with definitions for each column in the data sets.

[key]: https://floridalobbyist.gov/CompensationReportSearch/DownloadDataChart

```{r var_defs, echo=FALSE}
var_url <- "https://floridalobbyist.gov/CompensationReportSearch/DownloadDataChart"
read_html(var_url) %>% 
  html_node("table") %>% 
  html_table() %>% 
  mutate(
    `Data Element` = glue("`{make_clean_names(`Data Element`)}`"),
    `Definition` = str_trunc(Definition, width = 80)
  ) %>% 
  kable()
```

## Import

To create a single clean data file of lobbyist activity, we will first download each file locally
and read as a single data frame.

### Download

The data is separated into quarterly files by year. The URL for each file takes a consistent
format. With the `tidyr::expand_grid()` and `glue::glue()` functions, we can create a URL for all
bombinations of year, quarter, and branch.

```{r list_year_urls}
urls <- 
  expand_grid(
    year = 2008:2019,
    quarter = 1:4,
    branch = c("Executive", "Legislative")
  ) %>% 
  mutate(
    url = glue("https://floridalobbyist.gov/reports/{year}_Quarter{quarter}_{branch}.txt")
  )
```

```{r urls_view, echo=FALSE}
print(urls)
```

```{r pull_urls}
urls <- pull(urls)
```

This creates `r n_distinct(urls)` distinct URLs, each corresponding to a separate file.

```{r print_urls, results='asis'}
md_bullet(head(urls))
```

We can download each TXT file to the `/fl/data/raw` directory.

```{r create_raw_dir}
raw_dir <- dir_create(here("fl", "lobbying", "comp", "data", "raw"))
```

```{r download_raw, eval=FALSE}
if (!all_files_new(raw_dir, glob = "*.txt$")) {
  for (url in urls) {
    download.file(url, destfile = str_c(raw_dir, basename(url), sep = "/"))
  }
}
```

```{r list_files, echo=FALSE}
dir_info(raw_dir) %>% 
  mutate(path = str_remove(path, here())) %>% 
  select(
    path, 
    type,
    size,
    birth_time
  )
```

### Read

```{r read_raw}
read_quiet <- function(...) {
  suppressWarnings(suppressMessages(read_delim(...)))
}
fllc <- map_dfr(
  .x = dir_ls(raw_dir),
  .f = read_quiet,
  delim = "\t",
  escape_backslash = FALSE,
  escape_double = FALSE,
  col_types = cols(
    .default = col_character(),
    REPORT_QUARTER = col_factor(
      levels = c(
        "January - March",
        "April - June",
        "July - September",
        "October - December"
      )
    ),
    SUBMISSION_DATE = col_date_usa(),
    REPORT_YEAR = col_double(),
    TOTAL_COMPENSATION_RANGE = col_factor(
      levels = c(
        "$0.00", 
        "$1.00-$49,999.00",
        "$50,000.00-$99,999.00", 
        "$100,000.00-$249,999.00", 
        "$250,000.00-$499,999.00", 
        "$500,000.00-$999,999.00",
        "$1,000,000.00"
      )
    )
  )
)

fllc <- fllc %>% 
  clean_names("snake") %>% 
  rename_at(
    .vars = vars(7:14),
    .funs = ~str_c("firm", ., sep = "_")
  )
```

Despite each quarterly file ostensibly containing all data of the same type, the files really
contain _three_ types of records, each with a different number of columns. We can split the
combined data frame into a list of data frames and then remove from each the empty columns.

## Explore

```{r glimpse}
glimpse(fllc, max.level = 1)
```

## Normalize

### Address

```{r address_norm}
fllc <- fllc %>% 
  unite(
    col = "firm_address_full",
    starts_with("firm_address"),
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  unite(
    col = "principal_address_full",
    starts_with("principal_address"),
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  unite(
    col = "prime_firm_address_full",
    starts_with("prime_firm_address"),
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  mutate_at(
    .vars = vars(contains("address_full")),
    .funs = list(norm = normal_address),
    abbs = usps_street
  ) %>% 
  select(
    -ends_with("address_full")
  ) %>% 
  mutate_if(is_character, na_if, "") %>% 
  rename_at(
    .vars = vars(ends_with("address_full_norm")),
    .funs = ~str_replace(., "full_norm", "norm")
  )
```

```{r address_view}
fllc %>% 
  select(starts_with("firm_address")) %>% 
  distinct() %>% 
  sample_frac()
```

### ZIP

```{r zip_norm}
fllc <- fllc %>% 
  mutate_at(
    .vars = vars(ends_with("postal_code")),
    .funs = list(norm = normal_zip),
    na_rep = TRUE
  ) %>% 
  rename_all(
    .funs = ~str_replace(., "postal_code", "zip")
  )
```

```{r zip_prog}
progress_table(
  fllc$firm_zip,
  fllc$firm_zip_norm,
  fllc$principal_zip,
  fllc$principal_zip_norm,
  fllc$prime_firm_zip,
  fllc$prime_firm_zip_norm,
  compare = valid_zip
)
```

### State

```{r state_norm}
fllc <- fllc %>% 
  mutate_at(
    .vars = vars(contains("state")),
    .funs = list(norm = normal_state),
    na_rep = TRUE
  ) %>% 
  rename_all(
    .funs = ~str_replace(., "state_name", "state")
  )
```

```{r state_prog}
progress_table(
  fllc$firm_state,
  fllc$firm_state_norm,
  fllc$principal_state,
  fllc$principal_state_norm,
  fllc$prime_firm_state,
  fllc$prime_firm_state_norm,
  compare = valid_state
)
```

```{r state_view}
count(fllc, firm_state, firm_state_norm, sort = TRUE)
```

### Phone

```{r phone_norm}
fllc <- fllc %>% 
  mutate_at(
    .vars = vars(ends_with("phone_number")),
    .funs = list(norm = normal_phone),
  ) %>% 
  rename_all(
    .funs = ~str_replace(., "phone_number", "phone")
  )
```

```{r phone_view}
fllc %>% 
  select(starts_with("firm_phone")) %>% 
  distinct() %>% 
  sample_frac()
```

### City

```{r city_norm}
fllc <- fllc %>% 
  mutate_at(
    .vars = vars(contains("city")),
    .funs = list(norm = normal_city),
    abbs = usps_city,
    states = c("FL", "DC", "FLORIDA"),
    na = invalid_city,
    na_rep = TRUE
  ) %>% 
  rename_all(
    .funs = ~str_replace(., "city_name", "city")
  )
```

```{r city_swap}
fllc <- fllc %>%
  # firm
  left_join(
    y = zipcodes,
    by = c(
      "firm_state_norm" = "state",
      "firm_zip_norm" = "zip"
    )
  ) %>% 
  rename(firm_city_match = city) %>% 
  mutate(
    firm_match_abb = is_abbrev(firm_city_norm, firm_city_match),
    firm_match_dist = str_dist(firm_city_norm, firm_city_match),
    firm_city_swap = if_else(
      condition = firm_match_abb | firm_match_dist == 1,
      true = firm_city_match,
      false = firm_city_norm
    )
  ) %>% 
  # firm
  left_join(
    y = zipcodes,
    by = c(
      "principal_state_norm" = "state",
      "principal_zip_norm" = "zip"
    )
  ) %>% 
  rename(principal_city_match = city) %>% 
  mutate(
    principal_match_abb = is_abbrev(principal_city_norm, principal_city_match),
    principal_match_dist = str_dist(principal_city_norm, principal_city_match),
    principal_city_swap = if_else(
      condition = principal_match_abb | principal_match_dist == 1,
      true = principal_city_match,
      false = principal_city_norm
    )
  ) %>% 
  # firm
  left_join(
    y = zipcodes,
    by = c(
      "prime_firm_state_norm" = "state",
      "prime_firm_zip_norm" = "zip"
    )
  ) %>% 
  rename(prime_firm_city_match = city) %>% 
  mutate(
    prime_firm_match_abb = is_abbrev(prime_firm_city_norm, prime_firm_city_match),
    prime_firm_match_dist = str_dist(prime_firm_city_norm, prime_firm_city_match),
    prime_firm_city_swap = if_else(
      condition = prime_firm_match_abb | prime_firm_match_dist == 1,
      true = prime_firm_city_match,
      false = prime_firm_city_norm
    )
  )
```

```{r city_prog}
city_prog <- progress_table(
  fllc$firm_city,
  fllc$firm_city_norm,
  fllc$firm_city_swap,
  fllc$principal_city,
  fllc$principal_city_norm,
  fllc$principal_city_swap,
  fllc$prime_firm_city,
  fllc$prime_firm_city_norm,
  fllc$prime_firm_city_swap,
  compare = valid_city
)

city_prog <- city_prog %>% 
  separate(
    col = stage,
    into = c("type", "stage"),
    sep = "_(?=city)"
  ) %>% 
  group_by(type) %>% 
  mutate(stage = as_factor(stage))
```

```{r progress_bar, echo=FALSE}
city_prog %>% 
  ggplot(aes(x = stage, y = prop_in)) +
  geom_hline(yintercept = 0.99) +
  geom_col(aes(fill = type), position = "dodge") +
  coord_cartesian(ylim = c(0, 1)) +
  scale_y_continuous(labels = percent) +
  scale_fill_brewer(palette = "Dark2", guide = FALSE) +
  labs(
    title = "Florida Lobbyist Compensation City Normalization",
    x = "Stage",
    y = "Percent Valid"
  ) +
  facet_wrap(~type, scales = "free")
```

```{r distinct_bar, echo=FALSE}
city_prog %>% 
  select(
    type,
    stage, 
    all = n_distinct,
    bad = n_diff
  ) %>% 
  mutate(good = all - bad) %>% 
  pivot_longer(c("good", "bad")) %>% 
  mutate(name = name == "good") %>% 
  ggplot(aes(x = stage, y = value)) +
  geom_col(aes(fill = name)) +
  scale_fill_brewer(palette = "Dark2") +
  scale_y_continuous(labels = comma) +
  theme(legend.position = "bottom") +
  labs(
    title = "Massachusetts City Normalization Progress",
    subtitle = "Distinct values, valid and invalid",
    x = "Stage",
    y = "Percent Valid",
    fill = "Valid"
  ) +
  facet_wrap(~type, scales = "free")
  
```

```{r}
fllc <- fllc %>% 
  select(
    -ends_with("city_match"),
    -ends_with("match_abb"),
    -ends_with("match_dist"),
    -contains("city_norm")
  ) %>% 
  rename_at(
    .vars = vars(ends_with("city_swap")),
    .funs = ~str_replace(., "swap", "norm")
  )
```

## Split

```{r group_split}
fllc <- fllc %>% 
  group_split(record_type) %>% 
  map(remove_empty, "cols") %>% 
  set_names(c("firm", "lob", "pri"))
```

The data with a `record_type` of "LOBBYIST" contains one row for every lobbyist alongside the firm for
which they work. There is no information on which particular clients that lobbyist is assigned.

```{r head_lob}
head(sample_frac(fllc$lob))
```

For "FIRM" records, there are not 16 variables for every firm listed, including geographic
information and the range of total compensation they have earned.

```{r head_firm}
glimpse(sample_frac(fllc$firm))
```

The "PRINCIPAL" records are the clients hiring firms (and their lobbyist) to conduct lobbying work.
The exact lobbyists working for each client account are _not_ listed, only the overal lobbying firm
hired.

```{r head_pri}
glimpse(sample_frac(fllc$pri))
```

## Export

```{r create_proc_dir}
proc_dir <- dir_create(here("fl", "lobbying", "comp", "data", "processed"))
```

```{r write_firm}
write_csv(
  x = fllc$firm,
  path = glue("{proc_dir}/fl_lobby_firm_comp.csv"),
  na = ""
)
```

```{r write_lob}
write_csv(
  x = fllc$lob,
  path = glue("{proc_dir}/fl_lobby_firms.csv"),
  na = ""
)
```

```{r write_pri}
write_csv(
  x = fllc$pri,
  path = glue("{proc_dir}/fl_lobby_pri_comp.csv"),
  na = ""
)
```
