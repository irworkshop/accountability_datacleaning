---
title: "Hawaii Lobbyists"
author: "Kiernan Nicholls"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
fs::dir_create(here::here("hi", "lobbying", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This package contains
functions custom made to help facilitate the processing of campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load_gh("kiernann/gluedown")
pacman::p_load(
  tidyverse, # data manipulation
  lubridate, # datetime strings
  jsonlite, # read json files
  magrittr, # pipe opperators
  janitor, # dataframe clean
  refinr, # cluster and merge
  scales, # format strings
  readxl, # read excel files
  knitr, # knit documents
  vroom, # read files fast
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here}
# where does this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Data

Data can be obtained by the [Hawaii State Ethics Commission][hec] via their [Socrata portal][hsp].

[hec]: https://ethics.hawaii.gov/
[hsp]: https://data.hawaii.gov/

```{r meta_read, echo=FALSE}
hi_meta <- fromJSON("https://data.hawaii.gov/api/views/gdxe-t5ff")
```

The relavent file is named `r quote(hi_meta$name)` with the ID of `r md_code(hi_meta$id)`. The file
was created at `r as_datetime(hi_meta$createdAt)`.

There are `r nrow(hi_meta$columns)` columns in the database.

```{r meta_cols}
hi_meta %>% 
  use_series("columns") %>% 
  as_tibble() %>% 
  select(
    position,
    fieldName,
    name,
    dataTypeName
  ) %>%
  mutate(fieldName = md_code(fieldName)) %>% 
  kable(col.names = c("col", "variable", "name", "type"))
```

This data does _not_ include the mailing addresses of the lobbyists and principal organizations.
After contacting the Ethics Commission, I was provided with an Excel file containing the additional
mailing address variable; this data will be processed and added to the site.

## Import

If the file containing addresses is found on disc, the wrangling will continue; otherwise, the
raw file will be read from the portal and not wrangled any futher.

```{r raw_dir}
raw_dir <- here("hi", "lobbying", "data", "raw")
dir_create(raw_dir)
```

```{r raw_read}
geo_file <- dir_ls(raw_dir, type = "file", glob = "*.xlsx") 
raw_file <- "https://data.hawaii.gov/api/views/gdxe-t5ff/rows.csv"

if (file_exists(geo_file)) {
  # read the excel file
  hilr <- 
     read_csv(
      file = format_csv(read_excel(geo_file)),
      skip = 1,
      col_names = c(
        "reg_name", "lob_name", "org_name", "lob_firm", "date_filed", "status", 
        "date_reg", "date_term", "lob_email", "lob_phone", "lob_ext", "lob_geo", 
        "lob_city", "lob_state", "lob_zip"
      ),
      col_types = cols(
        .default = col_character(),
        date_filed = col_date_usa(),
        date_reg = col_date_usa(),
        date_term = col_date_usa()
      )
    )
} else {
  # read the portal file
  hilr <- 
    read_csv(
      file = raw_file,
      col_types = cols(
        Registration = col_date_usa(),
        Termination = col_date_usa()
      )
    ) %>%
    # rename, reorder, and clean
    rename(
      lob_name = `Lobbyist Name`,
      org_name = `Organization Name`,
      session = `Lobby Year`
    ) %>% 
    select(-View, View) %>% 
    clean_names() %>% 
    mutate(view = str_extract(view, "(?<=\\()(.*)(?=\\))"))
  # stop the document
  knit_exit()
}
```

## Wrangle

### Phone

To normalize the lobbyist phone number variable, will will combine the number and extension with
`tidyr::unite()` and pass the united string to `campfin::normal_phone()`.

```{r phone_normal}
hilr <- hilr %>% 
  unite(
    lob_phone, lob_ext,
    col = "lob_phone_norm",
    sep = "x",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  mutate(
    lob_phone_norm = normal_phone(
      number = lob_phone_norm,
      na_bad = FALSE,
      rm_ext = FALSE
    )
  )
```

```{r phone_view, echo=FALSE}
hilr %>% 
  select(lob_phone, lob_ext, lob_phone_norm) %>% 
  distinct() %>% 
  sample_frac()
```

### Address

```{r address_normal}
hilr <- hilr %>%
  mutate(
    lob_addr_split = str_remove(lob_geo, glue(",\\s{lob_city},\\s{lob_state}\\s{lob_zip}.*$")),
    lob_addr_norm = normal_address(
      address = lob_addr_split,
      abbs = usps_street,
      na_rep = TRUE
    )
  ) %>% 
  select(-lob_addr_split)
```

```{r address_view, echo=FALSE}
hilr %>% 
  select(lob_geo, lob_addr_norm) %>% 
  distinct() %>% 
  sample_frac()
```

### ZIP

```{r zip_norm}
hilr <- hilr %>% 
  mutate(
    lob_zip_norm = normal_zip(
      zip = lob_zip,
      na_rep = TRUE
    )
  )
```

```{r zip_progress, echo=FALSE}
progress_table(
  hilr$lob_zip,
  hilr$lob_zip_norm,
  compare = valid_zip
)
```

### State

Aside from abbreviation the `lob_state` to the 2-digit USPS abbreviation, no other changes need
to be made to clean completely.

```{r state_abbrev}
hilr <- hilr %>% 
  mutate(
    lob_state_norm = normal_state(
      state = lob_state,
      abbreviate = TRUE
    )
  )
```

```{r state_progress}
progress_table(
  hilr$lob_state,
  hilr$lob_state_norm,
  compare = valid_state
)
```

### City

The `lob_city` variable is already quite clean

```{r normal_city}
hilr <- hilr %>% 
  mutate(
    lob_city_norm = normal_city(
      city = lob_city, 
      abbs = usps_city,
      states = c("HI", "DC", "HAWAII"),
      na = invalid_city,
      na_rep = TRUE
    )
  )
```

```{r swap_city}
hilr <- hilr %>% 
  left_join(
    y = zipcodes,
    by = c(
      "lob_state_norm" = "state",
      "lob_zip_norm" = "zip"
    )
  ) %>% 
  rename(city_match = city) %>% 
  mutate(
    match_abb = is_abbrev(lob_city_norm, city_match),
    match_dist = str_dist(lob_city_norm, city_match),
    lob_city_swap = if_else(
      condition = match_abb | match_dist == 1,
      true = city_match,
      false = lob_city_norm
    )
  ) %>% 
  select(
    -match_abb,
    -match_dist
  )
```

```{r city_progress}
progress_table(
  hilr$lob_city,
  hilr$lob_city_norm,
  hilr$lob_city_swap,
  compare = valid_city
)
```

## Export

```{r proc_dir}
proc_dir <- here("hi", "lobbying", "data", "processed")
dir_create(proc_dir)
```

```{r}
hilr %>% 
  select(
    -lob_city_norm,
    -city_match,
    -lob_city,
    -lob_state,
    -lob_zip
  ) %>% 
  rename(
    lob_phone_clean = lob_phone_norm,
    lob_addr_clean = lob_addr_norm,
    lob_zip_clean = lob_zip_norm,
    lob_state_clean = lob_state_norm,
    lob_city_clean = lob_city_swap
  ) %>% 
  write_csv(
    path = glue("{proc_dir}/hi_lobby_clean.csv"),
    na = ""
  )
```

