---
title: "Hawaii Contributions"
author: "Kiernan Nicholls"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
fs::dir_create(here::here("hi", "contribs", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give
journalists, policy professionals, activists, and the public at large a simple
way to search across huge volumes of public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each
dataset row as a transaction. For each transaction there should be (at least) 3
variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze,
and communicate these results. The `pacman` package will facilitate their
installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This
package contains functions custom made to help facilitate the processing of
campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load(
  tidyverse, # data manipulation
  lubridate, # datetime strings
  magrittr, # pipe operators
  janitor, # data frame clean
  refinr, # cluster and merge
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a
sub-directory of the more general, language-agnostic
[`irworkshop/accountability_datacleaning`][01] GitHub repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be
run as such. The project also uses the dynamic `here::here()` tool for file
paths relative to _your_ machine.

```{r where_here}
# where does this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects

## Data

Data is obtained from the [Hawaii Campaign Spending Commission][csc] (CSC). The
file can be found on the [Hawaii Open Data portal][odp]. There are two files,
one contributions received by Candidate committees and one for Noncandidate
committees. In both files, each record represents a campaign contribution made
from an individual, political party, or some other entity.

[csc]: https://ags.hawaii.gov/campaign/
[dop]: https://data.hawaii.gov/about

## Import

We can read both files into a single data frame with `purrr::map_df()` and 
`readr::read_csv()`.

```{r read_raw}
hic <- map_df(
  .x = c(
    "https://data.hawaii.gov/api/views/jexd-xbcg/rows.csv", # Candidates
    "https://data.hawaii.gov/api/views/rajm-32md/rows.csv" # Committees
  ),
  .f = read_csv,
  .id = "reg_type",
  col_types = cols(
    .default = col_character(),
    Date = col_date_usa(),
    Amount = col_double(),
    Aggregate = col_double()
  )
)
```

Then we will do some slight wrangling to the column names, types, and positions
for clarity.

```{r shape_raw}
hic <- hic %>%
  clean_names(case = "snake") %>%
  rename(
    cand_name = candidate_name,
    comm_name = noncandidate_committee_name,
    cont_type = contributor_type,
    cont_name = contributor_name,
    monetary = non_monetary_yes_or_no,
    category = non_monetary_category,
    description = non_monetary_description,
    in_state = in_out_state,
    zip = zip_code,
    reg_id = reg_no,
  ) %>% 
  mutate(
    reg_type = recode(reg_type, "1" = "Candidate", "2" = "Noncandidate"),
    reg_name = coalesce(cand_name, comm_name),
    monetary = equals(monetary, "N"),
    in_state = equals(in_state, "HI")
  ) %>% 
  select(
    date,
    reg_id,
    reg_type,
    reg_name,
    everything(),
    -comm_name,
    -cand_name
  )
```

## Explore

The data base has `r comma(nrow(hic))` rows of `r ncol(hic)` variables.

```{r glimpse}
head(hic)
tail(hic)
glimpse(sample_frac(hic))
```

### Missing

```{r glimpse_na}
col_stats(hic, count_na)
```

There are no columns missing the name, date, or amount used to identify a unique contribution.

### Duplicates

```{r dupe_flag}
hic <- flag_dupes(hic, everything())
```

There are `r sum(hic$dupe_flag)` rows that are complete duplicated of another.
They are flagged.

```{r dupe_view}
hic %>% 
  filter(dupe_flag) %>% 
  select(date, reg_name, cont_name, amount) %>% 
  arrange(date)
```

### Categorical

```{r glimpse_distinct}
col_stats(hic, n_distinct)
```

```{r plot_reg_type}
explore_plot(
  data = filter(hic, !is.na(reg_type)),
  var = reg_type,
  title = "Hawaii Recipient Types"
)
```

```{r plot_cont_type}
explore_plot(
  data = hic,
  var = cont_type,
  title = "Hawaii Contributor Types"
)
```

```{r plot_cont_monetary}
explore_plot(
  data = hic,
  var = monetary,
  title = "Hawaii Monetary Contributions"
)
```

```{r plot_cont_category}
explore_plot(
  data = filter(hic, !is.na(category)),
  var = category,
  title = "Hawaii Non-Monetary Categories"
)
```

```{r plot_office}
explore_plot(
  data = filter(hic, !is.na(office)),
  var = office,
  title = "Hawaii Recipeient Candidate for Office"
)
```

```{r plot_party}
explore_plot(
  data = filter(hic, !is.na(party)),
  var = party,
  title = "Hawaii Recipeient Candidate Party"
)
```

```{r plot_instate}
explore_plot(
  data = filter(hic, !is.na(in_state)),
  var = in_state,
  title = "Hawaii Contributor In-State"
)
```

```{r fix_range}
hic <- mutate(hic, range = str_remove_all(range, "\\s"))
```

```{r plot_range}
explore_plot(
  data = filter(hic, !is.na(range)),
  var = range,
  title = "Hawaii Contributor In-State"
)
```

### Continuous

#### Amounts

```{r summary_amount}
summary(hic$amount)
```

```{r amount_histogram, echo=FALSE}
hic %>%
  filter(amount > 1) %>% 
  ggplot(aes(amount)) +
  geom_histogram(fill = dark2["purple"], bins = 20) +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(
    breaks = c(1 %o% 10^(0:6)),
    labels = dollar,
    trans = "log10"
  ) +
  labs(
    title = "Hawaii Contribution Amount Distribution",
    x = "Amount",
    y = "Count"
  )
```

```{r amount_violin_reg_type, echo=FALSE}
hic %>% 
  filter(amount > 1) %>% 
  ggplot(
    mapping = aes(
      x = reorder(reg_type, X = amount, FUN = median, na.rm = TRUE), 
      y = amount,
      fill = reg_type
    )
  ) +
  geom_violin(
    trim = TRUE,
    draw_quantiles = c(0.25, 0.5, 0.75),
    scale = "area",
    adjust = 2
  ) +
  scale_y_continuous(
    breaks = c(1 %o% 10^(0:6)),
    trans = "log10",
    labels = dollar
  ) +
  scale_fill_brewer(
    type = "qual", 
    palette = "Dark2", 
    guide = FALSE
  ) +
  labs(
    title = "Hawaii Contribution Amount",
    subtitle = "by Recipient Type",
    x = "",
    y = "Expenditure Amount"
  ) +
  theme(panel.grid.major.x = element_blank())
```

```{r amount_violin_cont_type, echo=FALSE}
hic %>% 
  filter(
    amount > 1,
    cont_type %in% most_common(cont_type, 4)
  ) %>% 
  ggplot(
    mapping = aes(
      x = reorder(cont_type, X = amount, FUN = median, na.rm = TRUE), 
      y = amount,
      fill = cont_type
    )
  ) +
  geom_violin(
    trim = TRUE,
    draw_quantiles = c(0.25, 0.5, 0.75),
    scale = "area",
    adjust = 2
  ) +
  scale_y_continuous(
    breaks = c(1 %o% 10^(0:6)),
    trans = "log10",
    labels = dollar
  ) +
  scale_fill_brewer(
    type = "qual", 
    palette = "Dark2", 
    guide = FALSE
  ) +
  labs(
    title = "Hawaii Contribution Amount",
    subtitle = "by Contributor Type",
    x = "",
    y = "Expenditure Amount"
  ) +
  theme(panel.grid.major.x = element_blank())
```

#### Dates

```{r year_add}
hic <- mutate(hic, year = year(date))
```

```{r date_range}
min(hic$date)
sum(hic$year < 2000)
max(hic$date)
sum(hic$date > today())
```

## Wrangle

### Address

```{r address_norm}
hic <- hic %>% 
  # combine street addr
  unite(
    col = adress_full,
    starts_with("address"),
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  # normalize combined addr
  mutate(
    address_norm = normal_address(
      address = adress_full,
      abbs = usps_street,
      na_rep = TRUE
    )
  ) %>% 
  select(-adress_full)
```

```{r address_view}
hic %>% 
  select(starts_with("address")) %>% 
  distinct() %>% 
  sample_frac()
```

### ZIP

```{r zip_norm}
hic <- hic %>% 
  mutate(
    zip_norm = normal_zip(
      zip = zip,
      na_rep = TRUE
    )
  )
```

```{r zip_progress}
progress_table(
  hic$zip,
  hic$zip_norm,
  compare = valid_zip
)
```

### State

```{r}
prop_in(hic$state, valid_state)
count_vec(hic$state)
```

### City

```{r city_norm}
hic <- hic %>% 
  mutate(
    city_norm = normal_city(
      city = city, 
      abbs = usps_city,
      states = c("HI", "DC", "HAWAII"),
      na = invalid_city,
      na_rep = TRUE
    )
  )
```

```{r city_swap}
hic <- hic %>% 
  rename(cont_city = city) %>% 
  left_join(
    y = zipcodes,
    by = c(
      "state" = "state",
      "zip_norm" = "zip"
    )
  ) %>% 
  rename(city_match = city) %>% 
  mutate(
    match_abb = is_abbrev(city_norm, city_match),
    match_dist = str_dist(city_norm, city_match),
    city_swap = if_else(
      condition = !is.na(city_match) & (match_abb | match_dist == 1),
      true = city_match,
      false = city_norm
    )
  ) %>% 
  select(
    -match_abb,
    -match_dist,
    -city_match
  ) %>% 
  rename(city = cont_city)
```

```{r city_progress}
progress_table(
  hic$city,
  hic$city_norm,
  hic$city_swap,
  compare = c(valid_city, extra_city)
)
```

## Conclude

```{r glimpse_final}
glimpse(sample_frac(hic))
```

1. There are `r nrow(hic)` records in the database.
1. There are `r sum(hic$dupe_flag)` duplicate records in the database.
1. The range and distribution of `amount` and `date` seem reasonable.
1. There are `r sum(hic$na_flag)` records missing either recipient or date.
1. Consistency in geographic data has been improved with `campfin::normal_*()`.
1. The 5-digit `zip_norm` variable has been created with `campfin::normal_zip(hic$zip)`.
1. The 4-digit `year` variable has been created with `lubridate::year()`.

## Export

```{r clean_trim}
hic <- hic %>% 
  select(
    -city_norm,
    city_norm = city_swap
  )
```

```{r clean_write}
clean_dir <- dir_create(here("hi", "contribs", "data", "processed"))
clean_path <- path(clean_dir, "hi_cont_clean.csv")
write_csv(hic, path = clean_path, na = "")
file_size(clean_path)
guess_encoding(clean_path)
```
