---
title: "Mississippi Lobbying Expenditure Data Diary"
author: "Yanqi Xu"
date: "`r format(Sys.time())`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 3
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```
## Project


The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.


Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:


1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved


## Objectives


This document describes the process used to complete the following objectives:


1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction


## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

```{r p_load, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_current_gh("irworkshop/campfin")
pacman::p_load(
  rvest, # read html tables
  stringdist, # levenshtein value
  tidyverse, # data manipulation
  lubridate, # datetime strings
  tidytext, # string analysis
  magrittr, # pipe opperators
  janitor, # dataframe clean
  refinr, # cluster and merge
  knitr, # knit documents
  glue, # combine strings
  scales, #format strings
  here, # relative storage
  fs, # search storage 
  vroom, #read deliminated files
  readxl #read excel files
)
```

```{r fix_fun, echo=FALSE, collapse = TRUE}
# fix conflict
here <- here::here
print_all <- function(df) df %>% print(n = nrow(.)) 
```
This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.


The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.


## Download
Set the download directory first.
```{r create raw_dir}
# create a directory for the raw data
raw_dir <- here("ms", "lobby", "data", "raw","exp")

dir_create(raw_dir)
```
We downloaded the lobbyist compensation data from [The Secretary of Stateâ€™s Office] [03], and the data is as current as 2019.

[03]: https://www.sos.ms.gov/Elections-Voting/Documents/2019%20Lobbying%20Guide.pdf


## Reading
We discovered that the xls files are actually structured as html tables. We'll use the `rvest` package to read these files.
```{r read csv}
ms_exp_files <- list.files(raw_dir, pattern = "ms_lobby_exp.*", recursive = TRUE, full.names = TRUE)
# Create function to read a html table
read_web_tb <- function(file){
  df <- read_html(file) %>% html_node("table") %>% html_table(header = T)
  return(df)
}

ms_lobby_exp <- ms_exp_files %>% map(read_web_tb) %>% 
                   bind_rows() %>% 
                   clean_names()

ms_lobby_exp <- ms_lobby_exp %>% 
  mutate(filed = as.Date(filed, format = '%m/%d/%Y'),
         compensation = as.numeric(compensation %>% str_remove("\\$") %>% str_remove(","))) %>% 
  mutate_if(is.character, str_to_upper)
```
## Explore

### Duplicates

We'll use the `flag_dupes()` function to see if there are records identical to one another and flag the duplicates. A new variable `dupe_flag` will be created.

```{r flag dupe}
ms_lobby_exp <- flag_dupes(ms_lobby_exp, dplyr::everything())
tabyl(ms_lobby_exp$dupe_flag)
```
### Year
```{r plot yea, echo=FALSE}
ms_lobby_exp %>% 
  mutate(year = as.numeric(cycle_year)) %>% 
  filter(!is.na(compensation)) %>% 
  count(year, sort = T) %>% 
  mutate(on = is_even(year),) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(aes(fill = on)) +
  scale_x_continuous(breaks = 2011:2019) +
  scale_y_continuous(labels = comma) +
  scale_fill_brewer(
    type = "qual",
    palette = "Dark2"
  ) +
  labs(
    title = "Mississippi Lobbying Expenditures Count by Year",
    caption = "Source: Mississippi Elections Division: Lobbying",
    fill = "Election Year",
    x = "Year",
    y = "Distinct Expenditures"
  ) +
  theme(legend.position = "bottom")

```

```{r bar_med_plot, echo=FALSE}
ms_lobby_exp %>% 
  mutate(on = is_even(cycle_year)) %>%
  group_by(on, cycle_year) %>% 
  summarize(median = median(compensation, na.rm = TRUE)) %>% 
  ggplot(aes(x = cycle_year, y = median)) +
  geom_col(aes(fill = on)) +
  scale_y_continuous(labels = dollar) +
  scale_x_continuous(breaks = 2011:2019) +
  scale_fill_brewer(
    type = "qual",
    palette = "Dark2"
  ) +
  labs(
    title = "Mississippi Lobbying Median Expenditures by Year",
    caption = "Source: Mississippi Elections Division: Lobbying",
    fill = "Year",
    x = "Election Year",
    y = "Median Amount"
  ) +
  theme(legend.position = "bottom")
```

### Missing
There's no empty fields in the two data frames. 
```{r count_na}
ms_lobby_exp  %>% col_stats(count_na)
```
## Join
We'll join the expenditure data with the registration data frame that we cleaned before. 


```{r}
reg_dir <- here("ms", "lobby", "data", "processed","reg")
ms_lobby_reg <- read_csv(glue("{reg_dir}/ms_lobby_reg.csv"))
```

However, we will see that the first_name, and last_name in the `ms_lob_reg` dataframe don't constitue the full name to be matched in the expenditure record. So we will generate `first_name` and `last_name` fields in `ms_lob_exp` to be matched with their counterparts in the `reg`.


```{r join pre}
ms_lobby_reg <-  ms_lobby_reg %>% 
  select(client_name,
         client_telephone_norm,
         client_fax,
         client_address_norm,
         client_city_clean,
         client_state,
         client_zip5,
         certification_number,
         client_description,
         first_name,
         last_name,
         address_norm,
         city_clean,
         state,
         zip5,
         year)

ms_lobby_reg <- flag_dupes(ms_lobby_reg, dplyr::everything())
```
Since the registration information will not have an impact on the data integrity of the expenditure dataframe to which it's about to be joined, we can safely deduplicate it.

```{r join}
ms_lobby_exp <- ms_lobby_exp %>% 
  mutate(lobbyist_trim = lobbyist %>% str_remove("^DR. |^MR. |^MRS. |^MS. |^REV. |\\sESQ.$| \\sII.$|, SR.|, III.$|, III|, II|\\W*JR.$") %>% trimws() %>% str_squish(),
         first_name = str_match(lobbyist_trim, "(^\\S+)\\s")[,2],
         last_name = str_match(lobbyist_trim, "\\s(\\S+)$")[,2])

ms_lobby_exp_clean <- ms_lobby_exp %>% 
  left_join(ms_lobby_reg %>% filter(!dupe_flag) %>% select(-dupe_flag),
            by = c("entity_name" = "client_name",
            "first_name" = "first_name",
            "last_name" = "last_name",
            "cycle_year" = "year"))

ms_lobby_exp_clean %>% col_stats(count_na)
```
There are thousands of records missing address information because they don't a match in the `reg` dataframe.

## Export

```{r write clean}
clean_dir <- here("ms", "lobby", "data", "processed","exp")
dir_create(clean_dir)

ms_lobby_exp_clean %>% 
  select(-c(dupe_flag, lobbyist_trim)) %>% 
  write_csv(
    path = glue("{clean_dir}/ms_lobby_exp_clean.csv"),
    na = ""
  )
```


