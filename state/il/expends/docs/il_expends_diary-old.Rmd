---
title: "State Data"
author: "First Last"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  # it's nice to un-collapse df print
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This package contains
functions custom made to help facilitate the processing of campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_current_gh("kiernann/campfin")
pacman::p_load(
  stringdist, # levenshtein value
  RSelenium, # remote browser
  tidyverse, # data manipulation
  lubridate, # datetime strings
  magrittr, # pipe opperators
  janitor, # dataframe clean
  refinr, # cluster and merge
  scales, # format strings  
  knitr, # knit documents
  vroom, # read files fast
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here, collapse=TRUE}
# where dfs this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Data

> Chapter 10 ICLS 5/9-17, Illinois Compiled Statutes, governs the dissemination and use of campaign
disclosure data.
> 
> Any person who shall sell or utilize information from statements and reports filed with the State
Board of Elections for the purpose of soliciting contributions or for the purpose of business
solicitation is guilty of a Class B misdemeanor.
>
> Any person who alters or falsifies this information and publishes, circulates, or distributes
such altered or falsified information with the intent to misrepresent contributions received or
expenditures made by a candidate or political committee is guilty of a Class B misdemeanor.
> 
> Please review the following facts concerning campaign disclosure data files:
> 
> * Data is updated continuously.
> * This data may contain errors that have not yet been identified and corrected.
> * The Board provides files of campaign disclosure data; the Board does not provide software to
process this data.

>  Click the link below for the file type desired. Choose "Save" to copy the file to your computer.
The maximum number of records available for download is 25,000.
> ### File Type
> * Tab-Delimited Text File
> * CSV File
> * XML File

```{r raw_dir_create}
raw_dir <- here("il", "expends", "data", "raw")
dir_create(raw_dir)
```

```{r}
start_date <- as.Date("2008-01-01")
end_date <- today()
max_months <- interval(start_date, end_date) %/% months(1)
n_months <- seq(0, max_months)
```

```{r}
# open the driver with auto download options
remote_driver <- rsDriver(
  port = 4444L,
  browser = "firefox",
  extraCapabilities = makeFirefoxProfile(
    list(
      browser.download.dir = raw_dir,
      browser.download.folderList = 2L,
      browser.download.manager.showWhenStarting = FALSE,
      browser.helperApps.alwaysAsk.force = FALSE,
      browser.helperApps.neverAsk.saveToDisk = "text/plain",
      browser.helperApps.neverAsk.openFile = "text/plain"
    )
  )
)
```

```{r download_raw, warning=FALSE, error=FALSE, message=FALSE, collapse=TRUE, eval=FALSE}
remote_browser <- remote_driver$client
for (i in 0:1) {
  # navigate to the FL DOE download site
  url <- "https://www.elections.il.gov/CampaignDisclosure/ExpenditureSearchByAllExpenditures.aspx"
  remote_browser$navigate(url)
  
  # calculate the month start and end
  month_start <- start_date + months(i)
  month_end <- month_start + months(1) - days(1)
  
  # enter the month start
  start_keys <- list(format(month_start, "%m/%d/%Y"))
  start_css <- "#ContentPlaceHolder1_txtExpendedDate"
  remote_browser$findElement("css", start_css)$sendKeysToElement(start_keys)
  
  # enter the month end
  end_keys <- list(format(month_end, "%m/%d/%Y"))
  end_css <- "#ContentPlaceHolder1_txtExpendedDateThru"
  remote_browser$findElement("css", end_css)$sendKeysToElement(end_keys)
  
  # click the submit button
  remote_browser$findElement("css", "#ContentPlaceHolder1_btnSubmit")$clickElement()
  
  # click the download button
  remote_browser$findElement("css", "#ContentPlaceHolder1_lnkDownloadList")$clickElement()
  
  # click the tab-file link
  remote_browser$findElement("css", "#ContentPlaceHolder1_btnText")$clickElement()
  
  # rename the file after waiting
  Sys.sleep(30)
  file_path <- str_c(raw_dir, "Expenditures.txt", sep = "/")
  new_name <- str_c(raw_dir, glue("{month_start}_{month_end}_Expenditures.txt"), sep = "/")
  file_move(file_path, new_name)
}

# close the browser and driver
remote_browser$close()
remote_driver$server$stop()
```

## Import

```{r read_raw}
il <- map_df(
  .x = dir_ls(raw_dir),
  .f = read_delim,
  delim = "\t",
  escape_double = FALSE,
  escape_backslash = FALSE,
  col_types = cols(
    .default = col_character(),
    ExpndDate = col_date_usa(),
    Amount = col_double(),
    RptPdBegDate = col_date_usa(),
    RptPdEndDate = col_date_usa(),
    RptRcvdDate = col_date_usa()
  )
)

il <- il %>% 
  clean_names("snake") %>% 
  remove_empty("rows")
```

## Explore

```{r glimpse}
head(il)
tail(il)
glimpse(sample_frac(il))
```

### Missing

```{r glimpse_na}
glimpse_fun(il, count_na)
```

```{r flag_na}
il <- il %>% 
  mutate(payee_name = coalesce(beneficiary, candidate_name)) %>% 
  flag_na(received_by, payee_name, expnd_date, amount) %>% 
  select(-payee_name)

sum(il$na_flag)
```

### Duplicates

```{r flag_dupes}
il <- flag_dupes(il, everything())
sum(il$dupe_flag)
```

### Categorical

```{r glimpse_distinct}
glimpse_fun(il, n_distinct)
```

```{r type_bar, echo=FALSE}
explore_plot(
  data = il,
  var = expended_by_type,
  title = "Illinois Expenditures by Type",
  caption = "Source: Illinois State Board of Elections"
)
```

```{r support_bar, echo=FALSE}
explore_plot(
  data = drop_na(il, supporting_opposing),
  var = supporting_opposing,
  title = "Illinois Expenditures by Type",
  caption = "Source: Illinois State Board of Elections"
)
```

### Continuous

#### Amounts

```{r summary_amount}
summary(il$amount)
```

```{r amount_histogram, echo=FALSE}
il %>%
  ggplot(aes(amount)) +
  geom_histogram(fill = RColorBrewer::brewer.pal(3, "Dark2")[3]) +
  geom_vline(xintercept = median(il$amount), size = 1, linetype = 1) +
  geom_vline(xintercept = mean(il$amount), size = 1, linetype = 2) +
  scale_x_continuous(
    breaks = c(1 %o% 10^(0:6)),
    labels = dollar,
    trans = "log10"
  ) +
  labs(
    title = "Illinois Expenditures Amount Distribution",
    caption = "Source: Illinois State Board of Elections",
    x = "Amount",
    y = "Count"
  )
```

#### Dates

```{r add_year}
il <- mutate(il, expnd_year = year(expnd_date))
```

```{r date_range, collapse=TRUE}
min(il$expnd_date)
max(il$expnd_date)
sum(il$expnd_date > today())
```

## Wrangle

### Address

```{r normal_address}
if (packageVersion("tidyr") >= "0.8.3.9") {
  il <- il %>% 
  unite(
    col = address_full,
    starts_with("address"),
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  mutate(
    address_norm = normal_address(
      address = address_full,
      add_abbs = usps,
      na_rep = TRUE
    )
  )
} else {
  stop("Require tidyr 0.8.3.9000")
}
```

```{r view_address_change, echo=FALSE}
il %>% 
  select(starts_with("address")) %>%
  drop_na() %>% 
  sample_frac()
```

### ZIP

```{r count_zip_pre, collapse=TRUE}
n_distinct(il$zip)
prop_in(str_trim(il$zip), valid_zip, na.rm = TRUE)
length(setdiff(il$zip, valid_zip))
```

```{r normal_zip}
il <- il %>% 
  mutate(
    zip_norm = normal_zip(
      zip = zip,
      na_rep = TRUE
    )
  )
```

```{r count_zip_post, collapse=TRUE}
n_distinct(il$zip_norm)
prop_in(il$zip_norm, valid_zip, na.rm = TRUE)
length(setdiff(il$zip_norm, valid_zip))
```

### State

```{r count_state_pre, collapse=TRUE}
n_distinct(il$state)
prop_in(il$state, valid_state, na.rm = TRUE)
length(setdiff(il$state, valid_state))
```

```{r normal_state}
il <- il %>% 
  mutate(
    state_norm = normal_state(
      state = state,
      abbreviate = TRUE,
      na_rep = TRUE,
      valid = valid_state
    )
  )
```

```{r count_state_post, collapse=TRUE}
n_distinct(il$state_norm)
prop_in(il$state_norm, valid_state, na.rm = TRUE)
length(setdiff(il$state_norm, valid_state))
```

### City

```{r count_city_pre, collapse=TRUE}
n_distinct(il$city)
prop_in(str_to_upper(il$city), valid_city, na.rm = TRUE)
length(setdiff(il$city, valid_city))
```

#### Normalize

```{r normal_city}
il <- il %>% 
  mutate(
    city_norm = normal_city(
      city = city, 
      geo_abbs = usps_city,
      st_abbs = c("IL", "DC", "ILLINOIS"),
      na = na_city,
      na_rep = TRUE
    )
  )
```

```{r count_city_post_norm, collapse=TRUE}
n_distinct(il$city_norm)
prop_in(il$city_norm, valid_city, na.rm = TRUE)
length(setdiff(il$city_norm, valid_city))
```

#### Swap

```{r swap_city}
il <- il %>% 
  rename(city_raw = city) %>% 
  left_join(
    y = geo,
    by = c(
      "state_norm" = "state",
      "zip_norm" = "zip"
    )
  ) %>% 
  rename(city_match = city) %>% 
  mutate(
    match_dist = stringdist(city_norm, city_match),
    city_swap = if_else(
      condition = is_less_than(match_dist, 3),
      true = city_match,
      false = city_norm
    )
  )
```

```{r count_city_post_swap, collapse=TRUE}
n_distinct(il$city_swap)
prop_in(il$city_swap, valid_city, na.rm = TRUE)
length(setdiff(il$city_swap, valid_city))
```

#### Refine

```{r refine_city}
good_refine <- il %>% 
  mutate(
    city_refine = city_swap %>% 
      key_collision_merge() %>% 
      n_gram_merge(numgram = 1)
  ) %>% 
  filter(city_refine != city_swap) %>% 
  inner_join(
    y = geo,
    by = c(
      "city_refine" = "city",
      "state_norm" = "state",
      "zip_norm" = "zip"
    )
  )

nrow(good_refine)
```

```{r view_city_refines, echo=FALSE}
good_refine %>%
  count(
    state_norm, 
    zip_norm, 
    city_swap, 
    city_refine,
    sort = TRUE
  )
```

```{r join_refine}
il <- il %>% 
  left_join(good_refine) %>% 
  mutate(city_refine = coalesce(city_refine, city_swap))
```
#### Progress

We can make very few manual changes to capture the last few big invalid values. Local city
abbreviations (e.g., SPFD) often need to be changed by hand.

```{r view_final_bad}
il %>%
  filter(city_refine %out% valid_city) %>% 
  count(state_norm, city_refine, sort = TRUE) %>% 
  drop_na(city_refine)
```

```{r city_final}
il <- il %>% 
  mutate(
    city_final = city_refine %>% 
      str_replace("^STLOUIS$", "SAINT LOUIS") %>% 
      str_replace("^CHGO$", "CHICAGO") %>% 
      str_replace("^SPFLD$", "SPRINGFIELD")
  )
```

```{r progress_table, echo=FALSE}
progress_table <- tibble(
  stage = c("raw", "norm", "swap", "refine", "final"),
  prop_good = c(
    prop_in(str_to_upper(il$city_raw), valid_city, na.rm = TRUE),
    prop_in(il$city_norm, valid_city, na.rm = TRUE),
    prop_in(il$city_swap, valid_city, na.rm = TRUE),
    prop_in(il$city_refine, valid_city, na.rm = TRUE),
    prop_in(il$city_final, valid_city, na.rm = TRUE)
  ),
  total_distinct = c(
    n_distinct(str_to_upper(il$city_raw)),
    n_distinct(il$city_norm),
    n_distinct(il$city_swap),
    n_distinct(il$city_refine),
    n_distinct(il$city_final)
  ),
  unique_bad = c(
    length(setdiff(str_to_upper(il$city_raw), valid_city)),
    length(setdiff(il$city_norm, valid_city)),
    length(setdiff(il$city_swap, valid_city)),
    length(setdiff(il$city_refine, valid_city)),
    length(setdiff(il$city_final, valid_city))
  )
)

diff_change <- progress_table$unique_bad[5]-progress_table$unique_bad[1]
prop_change <- diff_change/progress_table$unique_bad[1]
```

Still, our progress is significant without having to make a single manual or unconfident change.
The percent of valid cities increased from `r percent(progress_table$prop_good[1])` to 
`r percent(progress_table$prop_good[5])`. The number of total distinct city values decreased from
`r comma(progress_table$total_distinct[1])` to `r comma(progress_table$total_distinct[5])`. The
number of distinct invalid city names decreased from `r comma(progress_table$unique_bad[1])` to
only `r comma(progress_table$unique_bad[5])`, a change of `r percent(prop_change)`.

```{r print_progress, echo=FALSE}
kable(
  x = progress_table,
  format = "markdown", 
  digits = 4,
  col.names = c("Normalization Stage", "Total Distinct", "Percent Valid", "Unique Invalid")
)
```

```{r wrangle_bar_prop, echo=FALSE}
progress_table %>% 
  mutate(stage = as_factor(stage)) %>% 
  ggplot(aes(x = stage, y = prop_good)) +
  geom_hline(yintercept = 0.99) +
  geom_col(fill = RColorBrewer::brewer.pal(3, "Dark2")[2]) +
  coord_cartesian(ylim = c(0.75, 1)) +
  scale_y_continuous(labels = percent) +
  labs(
    title = "Missouri Expenditures Payee City Progress",
    subtitle = "Percent of total values contained in pre-defined list of cities",
    caption = "Source: Missouri Ethics Commission",
    x = "Wrangling Stage",
    y = "Proportion Valid Cities"
  )
```

```{r wrangle_bar_distinct, echo=FALSE}
progress_table %>% 
  mutate(stage = as_factor(stage)) %>% 
  select(-prop_good) %>% 
  mutate(total_distinct = total_distinct - unique_bad) %>% 
  rename(
    All = total_distinct,
    Invalid = unique_bad
  ) %>% 
  gather(
    -stage,
    key = "key",
    value = "value"
  ) %>% 
  ggplot(aes(x = stage, y = value)) +
  geom_col(aes(fill = key)) +
  scale_fill_brewer(type = "qual", palette = "Dark2") +
  scale_y_continuous(labels = comma) +
  labs(
    title = "Missouri Expenditures Payee City Progress",
    subtitle = "Total distinct number of city values",
    caption = "Source: Missouri Ethics Commission",
    fill = "Distinct Values",
    x = "Wrangling Stage",
    y = "Number of Expenditures"
  )
```

## Conclude

1. There are `r nrow(il)` records in the database.
1. There are `r sum(il$dupe_flag)` duplicate records in the database (`dupe_flag`).
1. The range and distribution of `amount` and `date` are reasomable.
1. There are `r sum(il$na_flag)` records missing either a payee name (`na_flag`).
1. Consistency in geographic data has been improved with `campfin::normal_*()`.
1. The 5-digit `zip_norm` variable has been created with `campfin::normal_zip()`.
1. The 4-digit `expnd_year` variable has been created with `lubridate::year()`.

## Export

```{r create_proc_dir}
proc_dir <- here("il", "expends", "data", "processed")
dir_create(proc_dir)
```

```{r write_clean}
il %>% 
  select(
    -city_norm,
    -city_swap,
    -city_match,
    -city_swap,
    -match_dist,
    -city_refine
  ) %>% 
  write_csv(
    path = glue("{proc_dir}/il_expends_clean.csv"),
    na = ""
  )
```
