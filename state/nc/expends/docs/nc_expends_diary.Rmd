---
title: "North Carolina Expenditures"
author: "Kiernan Nicholls"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
if (!interactive()) {
  options(width = 99)
  set.seed(10753)
}
```

## Project

The Accountability Project is an effort to cut across data silos and give
journalists, policy professionals, activists, and the public at large a simple
way to search across huge volumes of public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each
dataset row as a transaction. For each transaction there should be (at least) 3
variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze,
and communicate these results. The `pacman` package will facilitate their
installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This
package contains functions custom made to help facilitate the processing of
campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load(
  tidyverse, # data manipulation
  lubridate, # datetime strings
  magrittr, # pipe opperators
  tidytext, # text analysis
  janitor, # dataframe clean
  batman, # parse logical
  refinr, # cluster and merge
  scales, # format strings
  rvest, # read html files
  knitr, # knit documents
  vroom, # read files fast
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a
sub-directory of the more general, language-agnostic
[`irworkshop/accountability_datacleaning`][01] GitHub repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be
run as such. The project also uses the dynamic `here::here()` tool for file
paths relative to _your_ machine.

```{r where_here, collapse=TRUE}
# where does this document knit?
here::here()
```

## Data

Data is obtained from the North Carolina State Board of Elections (NC SBoE).

> The State Board of Elections (State Board) is the state agency charged with
the administration of the elections process and campaign finance disclosure and
compliance.

> The state's Campaign Reporting Act applies to:
>
>  * all candidates for public office;  
>  * all political party groups and political action committees;  
>  * all groups organized to support or oppose a referendum;  
>  * every person or group participating in activities that support or oppose
the nomination or election of one or more clearly identified candidates, or a
political party or a referendum.


### Download

To download the data, perform a [Transaction Entity Search][03] for type
"Expenditure" from 2008-01-01 to `r today()`.

>  This page allows for searching through the NC SBoE Campaign Finance database
of transactions that committees have received (Receipts) or spent
(Expenditures).  Report data that is imported does not appear on our website in
real-time.  Our website updates overnight each weeknight.  All data imported
during a business day will appear on our website the following day.

[03]: https://cf.ncsbe.gov/CFTxnLkup/

```{r raw_dir}
raw_dir <- dir_create(here("nc", "expends", "data", "raw")) 
```

### Read

```{r read_raw}
nc <- read_csv(
  file = path(raw_dir, "transinq_results.csv"),
  na = c("NA", "", "Not Available"),
  skip = 1,
  col_names = c(
    "payee_name",
    "payee_street1",
    "payee_street2",
    "payee_city",
    "payee_state",
    "payee_zip",
    "profession",
    "employer",
    "transction_type",
    "comm_name",
    "comm_id",
    "comm_street1",
    "comm_street2",
    "comm_city",
    "comm_state",
    "comm_zip",
    "report_name",
    "date",
    "account_code",
    "amount",
    "form_of_payment",
    "purpose",
    "referendum_name",
    "declaration",
    "supports"
  ),
  col_types = cols(
    .default = col_character(),
    date = col_date_usa(),
    amount = col_double()
  )
) %>% 
  mutate_if(is_character, str_to_upper) %>% 
  mutate(supports = equals(declaration, "SUPPORT"))
```

## Explore

```{r glimpse}
head(nc)
tail(nc)
glimpse(sample_frac(nc))
```

### Missing

```{r missing_glimpse}
glimpse_fun(nc, count_na)
```

There seems to be a regular block of records missing the variables needed to properly identify a
transaction. We can flag those expenditures with `campfin::flag_na()`.

```{r missing_flag}
nc <- nc %>% flag_na(payee_name, comm_name, date, amount)
sum(nc$na_flag)
percent(mean(nc$na_flag))
```

### Duplicates

There are a fairly significant number of duplicate records in the database. It's possible for a 
committee to make multiple legitimate expenditures to the same vendor, on the same day, for the
same amount. Still, we will flag these records with `campfin::dupe_flag()`.

```{r dupe_flag}
nc <- flag_dupes(nc, everything())
sum(nc$dupe_flag)
percent(mean(nc$dupe_flag))
```

### Categorical

We can check the distribution of categorical variables to gain a better understanding as to what
kind of expenditures are being made.

```{r glimpse_distinct}
glimpse_fun(nc, n_distinct)
```

We can use `campfin::explore_plot()` to explore the distribution of the least distinct categorical
variables.

```{r type_bar, echo=FALSE}
explore_plot(
  data = nc,
  var = transction_type,
  flip = TRUE,
  palette = "Dark2",
  title = "North Carolina Expenditure Types",
  caption = "Source: NC SBoE"
)
```

```{r method_bar, echo=FALSE}
explore_plot(
  data = nc,
  var = form_of_payment,
  flip = TRUE,
  palette = "Dark2",
  title = "North Carolina Expenditure Payment Method",
  caption = "Source: NC SBoE"
)
```

```{r support_bar, echo=FALSE}
explore_plot(
  data = drop_na(nc, supports),
  var = supports,
  flip = FALSE,
  palette = "Dark2",
  title = "North Carolina Expenditure Supports Candidate/Issue",
  caption = "Source: NC SBoE"
)
```

We can use `tidytext::unnest_tokens()` and `ggplot2::geom_col()` to explore the most frequent
word usage of the long-form `purpose` variable.

```{r purpose_bar, echo=FALSE, fig.height=10}
nc %>% 
  unnest_tokens(word, purpose) %>% 
  anti_join(stop_words) %>% 
  count(word, sort = TRUE) %>%
  drop_na(word) %>% 
  head(30) %>% 
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_col(aes(fill = n)) +
  coord_flip() +
  scale_fill_gradient(guide = FALSE) +
  labs(
    title = "North Carolina Expenditure Supports Candidate/Issue",
    caption = "Source: NC SBoE",
    x = "Word",
    y = "Frequency"
  )
```

### Continuous

We should also check the range and distribution of continuous variables.

#### Amounts

```{r summary_amount}
summary(nc$amount)
sum(nc$amount <= 0, na.rm = TRUE)
```

```{r amount_histogram, echo=FALSE}
nc %>%
  filter(amount >= 1) %>% 
  ggplot(aes(amount)) +
  geom_histogram(fill = RColorBrewer::brewer.pal(3, "Dark2")[3]) +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(
    breaks = c(1 %o% 10^(0:6)),
    labels = dollar,
    trans = "log10"
  ) +
  labs(
    title = "North Carolina Expenditure Amount Distribution",
    caption = "Source: NC SBoE",
    x = "Amount",
    y = "Count"
  )
```

```{r amount_box_type, echo=FALSE}
nc %>%
  filter(amount > 1) %>% 
  drop_na(transction_type) %>%
  filter(transction_type %in% most_common(nc$transction_type)) %>% 
  ggplot(
    mapping = aes(
      x = reorder(
        x = transction_type, 
        X = amount, 
        FUN = median, 
        na.rm = TRUE
      ), 
      y = amount
    )
  ) +
  geom_violin(
    mapping = aes(fill = transction_type)
  ) +
  scale_y_continuous(
    breaks = c(1 %o% 10^(0:6)),
    labels = dollar,
    trans = "log10"
  ) +
  scale_fill_brewer(
    type = "qual",
    palette = "Dark2",
    guide = FALSE,
  ) +
  labs(
    title = "North Carolina Expenditure Amount Range by Transaction Type",
    caption = "Source: NC SBoE",
    x = "Transaction Type",
    y = "Amount"
  )
```

```{r amount_box_method, echo=FALSE}
nc %>%
  filter(amount > 1) %>% 
  drop_na(form_of_payment) %>%
  filter(form_of_payment %in% most_common(form_of_payment)) %>% 
  ggplot(
    mapping = aes(
      x = reorder(
        x = form_of_payment, 
        X = amount, 
        FUN = median, 
        na.rm = TRUE
      ), 
      y = amount
    )
  ) +
  geom_violin(
    mapping = aes(fill = form_of_payment)
  ) +
  scale_y_continuous(
    breaks = c(1 %o% 10^(0:6)),
    labels = dollar,
    trans = "log10"
  ) +
  scale_fill_brewer(
    type = "qual",
    palette = "Dark2",
    guide = FALSE,
  ) +
  labs(
    title = "North Carolina Expenditure Amount Range by Transaction Type",
    caption = "Source: NC SBoE",
    x = "Transaction Type",
    y = "Amount"
  )
```

#### Dates

We can add a `year` variable using `lubridate::year()`.

```{r add_year}
nc <- mutate(nc, year = year(date))
```

The `date` variable is very clean, with `r sum(nc$year < 2008, na.rm = TRUE)`
records before 2008 and `r sum(nc$date > today(), na.rm = TRUE)` records after `r today()`.

```{r date_range, collapse=TRUE}
min(nc$date, na.rm = TRUE)
sum(nc$year < 2008, na.rm = TRUE)
max(nc$date, na.rm = TRUE)
sum(nc$date > today(), na.rm = TRUE)
```

```{r year_bar_count, echo=FALSE}
nc %>% 
  count(year, sort = T) %>% 
  mutate(on = is_even(year),) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col(aes(fill = on)) +
  scale_x_continuous(breaks = 2008:2019) +
  scale_y_continuous(labels = comma) +
  scale_fill_brewer(
    type = "qual",
    palette = "Dark2"
  ) +
  labs(
    title = "North Carolina Expenditure Count by Year",
    caption = "Source: NC SBoE",
    fill = "Election Year",
    x = "Year",
    y = "Distinct Expenditures"
  ) +
  theme(legend.position = "bottom")
```

```{r year_bar_median, echo=FALSE}
nc %>% 
  drop_na(year) %>% 
  mutate(on = is_even(year),) %>%
  group_by(on, year) %>% 
  summarize(median = median(amount, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = median)) +
  geom_col(aes(fill = on)) +
  scale_y_continuous(labels = dollar) +
  scale_x_continuous(breaks = 2008:2019) +
  scale_fill_brewer(
    type = "qual",
    palette = "Dark2"
  ) +
  labs(
    title = "North Carolina Expenditure Median Amount by Year",
    subtitle = "Are campaigns becoming cheaper over time?",
    caption = "Source: NC SBoE",
    fill = "Election Year",
    x = "Year",
    y = "Median Amount"
  ) +
  theme(legend.position = "bottom")
```

```{r year_bar_total, echo=FALSE}
nc %>% 
  drop_na(year) %>% 
  mutate(on = is_even(year),) %>%
  group_by(on, year) %>% 
  summarize(sum = sum(amount, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = sum)) +
  geom_col(aes(fill = on)) +
  scale_y_continuous(labels = dollar) +
  scale_x_continuous(breaks = 2008:2019) +
  scale_fill_brewer(
    type = "qual",
    palette = "Dark2"
  ) +
  labs(
    title = "North Carolina Expenditure Total Amount by Year",
    subtitle = "Campaigns are not becoming cheaper overall",
    caption = "Source: NC SBoE",
    fill = "Election Year",
    x = "Year",
    y = "Total Amount"
  ) +
  theme(legend.position = "bottom")
```

```{r month_amount_line, echo=FALSE}
nc %>%
  drop_na(date) %>% 
  mutate(
    month = month(date),
    on = is_even(year),
  ) %>%
  group_by(month, on) %>%
  summarize(sum = sum(amount, na.rm = TRUE)) %>% 
  ggplot(aes(x = month, y = sum)) +
  geom_line(aes(color = on), size = 2) +
  scale_y_continuous(labels = dollar) +
  scale_x_continuous(labels = month.abb, breaks = 1:12) +
  scale_color_brewer(
    type = "qual",
    palette = "Dark2"
  ) +
  labs(
    title = "North Carolina Expenditure Total Amount by Month",
    subtitle = "Money is spent right before the election",
    caption = "Source: NC SBoE",
    fill = "Election Year",
    x = "Month",
    y = "Total Amount"
  ) +
  theme(legend.position = "bottom")
```

```{r cycle_amount_line, echo=FALSE}
nc %>% 
  drop_na(date, amount) %>% 
  select(date, year, amount) %>% 
  mutate(
    off = !is_even(year),
    cycle = as.character(if_else(!off, year, year - 1L)),
    month = if_else(off, month(date), month(date) + 12)
  ) %>% 
  group_by(cycle, off, month) %>% 
  summarize(mean = mean(amount)) %>% 
  ggplot(mapping = aes(x = month, y = mean)) +
  geom_vline(xintercept = 11, color = "grey10") +
  geom_line(aes(color = cycle), size = 1) +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  scale_x_continuous(labels = rep(month.abb, 2)[is_even(1:24)], breaks = seq(1, 24, 2)) +
  scale_y_continuous(labels = dollar) +
  labs(
    title = "North Carolina Expenditure Mean Amount by Month in Cycle",
    caption = "Source: NC SBoE",
    color = "Election Cycle",
    x = "Month in Cycle",
    y = "Mean Amount"
  )
```

## Wrangle

To improve the searchability of the database, we can perform some functional text normalization of
geographic data. Here, we have geographic data for both the expender and payee.

### Adress

```{r address_unite_norm}
nc <- nc %>% 
  unite(
    starts_with("payee_street"),
    col = payee_street,
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  unite(
    starts_with("comm_street"),
    col = comm_street,
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  mutate_at(
   .vars = vars(ends_with("street")),
   .funs = list(norm = normal_address),
   abbs = usps_street,
   na = invalid_city,
   na_rep = TRUE
  ) %>% 
  select(
    -ends_with("street")
  )
```

### States

```{r state_normal}
nc <- nc %>%
  mutate_at(
    .vars = vars(ends_with("state")),
    .funs = str_replace_all,
    "^N$", "NC"
  ) %>% 
  mutate_at(
   .vars = vars(ends_with("state")),
   .funs = list(norm = normal_state),
   abbreviate = TRUE,
   na = c("", "NA"),
   na_rep = TRUE,
   valid = valid_state
  )
```

```{r state_progress}
progress_table(
  nc$payee_state,
  nc$payee_state_norm,
  compare = valid_state
)
```

### Zip

```{r zip_normal}
nc <- nc %>%
  mutate_at(
   .vars = vars(ends_with("zip")),
   .funs = list(norm = normal_zip),
   na = c("", "NA"),
   na_rep = TRUE
  )
```

```{r zip_progress}
progress_table(
  nc$payee_zip,
  nc$payee_zip_norm,
  nc$comm_zip,
  nc$comm_zip_norm,
  compare = valid_zip
)
```

### City

```{r city_normal}
nc <- nc %>% 
  mutate_at(
   .vars = vars(ends_with("city")),
   .funs = list(norm = normal_city),
   abbs = usps_city,
   states = c("NC", "DC"),
   na = invalid_city,
   na_rep = TRUE
  )
```

```{r city_match}
nc <- nc %>% 
  left_join(
    y = zipcodes,
    by = c(
      "payee_state_norm" = "state",
      "payee_zip_norm" = "zip"
    )
  ) %>% 
  rename(payee_city_match = city) %>% 
  left_join(
    y = zipcodes,
    by = c(
      "comm_state_norm" = "state",
      "comm_zip_norm" = "zip"
    )
  ) %>% 
  rename(comm_city_match = city)
```

```{r city_swap}
nc <- nc %>%
  # check and swap payee city
  mutate(
    match_abb = is_abbrev(payee_city_norm, payee_city_match),
    match_dist = str_dist(payee_city_norm, payee_city_match),
    payee_city_swap = if_else(
      condition = !is.na(payee_city_match) & (match_abb | match_dist <= 1),
      true = payee_city_match,
      false = payee_city_norm
    )
  ) %>% 
  # check and swap committee city
  mutate(
    match_abb = is_abbrev(comm_city_norm, comm_city_match),
    match_dist = str_dist(comm_city_norm, comm_city_match),
    comm_city_swap = if_else(
      condition = !is.na(comm_city_match) & (match_abb | match_dist <= 1),
      true = comm_city_match,
      false = comm_city_norm
    )
  )
```

```{r city_prog_payee}
progress_table(
  nc$payee_city,
  nc$payee_city_norm,
  nc$payee_city_swap,
  compare = valid_city
)
```

```{r city_prog_comm}
progress_table(
  nc$comm_city,
  nc$comm_city_norm,
  nc$comm_city_swap,
  compare = valid_city
)
```

```{r city_prog, echo=FALSE}
progress <- progress_table(
  nc$payee_city,
  nc$payee_city_norm,
  nc$payee_city_swap,
  compare = valid_city
)
```

```{r progress_bar, echo=FALSE}
progress %>% 
  ggplot(aes(x = stage, y = prop_in)) +
  geom_hline(yintercept = 0.99) +
  geom_col(fill = RColorBrewer::brewer.pal(3, "Dark2")[3]) +
  coord_cartesian(ylim = c(0.75, 1)) +
  scale_y_continuous(labels = percent) +
  labs(
    title = "Massachusetts City Normalization Progress",
    x = "Stage",
    y = "Percent Valid"
  )
```

More importantly, the number of distinct values decreased each stage. We were
able to confidently change many distinct invalid values to their valid
equivilent.

```{r distinct_bar}
progress %>% 
  select(
    stage, 
    all = n_distinct,
    bad = n_diff
  ) %>% 
  mutate(good = all - bad) %>% 
  pivot_longer(c("good", "bad")) %>% 
  mutate(name = name == "good") %>% 
  ggplot(aes(x = stage, y = value)) +
  geom_col(aes(fill = name)) +
  scale_fill_brewer(palette = "Dark2") +
  scale_y_continuous(labels = comma) +
  theme(legend.position = "bottom") +
  labs(
    title = "Massachusetts City Normalization Progress",
    subtitle = "Distinct values, valid and invalid",
    x = "Stage",
    y = "Percent Valid",
    fill = "Valid"
  )
```

## Conclude

1. There are `r nrow(nc)` records in the database
1. There are `r sum(nc$dupe_flag)` (`r percent(mean(nc$dupe_flag))`) duplicate records
1. The range and distribution of `amount` and `date` are reasonable
1. There are `r sum(nc$na_flag)` (`r percent(mean(nc$na_flag))`) records missing names
1. Consistency in geographic data has been improved with `campfin::normal_*()`
1. The 5-digit `zip_norm` variable has been created with `campfin::normal_zip()`
1. The 4-digit `year` variable has been created with `lubridate::year()`

## Export

```{r clean_rename}
nc <- nc %>% 
  select(
  -payee_city_match,
  -comm_city_match,
  -payee_city_norm,
  -comm_city_norm,
  -match_abb,
  -match_dist,
)

nc <- nc %>% 
  rename_all(str_replace, "_(norm|swap)$", "_clean")
```

```{r clean_write}
clean_dir <- dir_create(here("nc", "expends", "data", "clean"))
clean_path <- path(clean_dir, glue("nc_expends_{today()}.csv"))
write_csv(nc, clean_path, na = "")
file_size(clean_path)
guess_encoding(clean_path)
```
