---
title: "North Carolina Lobbyists"
author: "Yanqi Xu"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
fs::dir_create(here::here("nc", "lobby", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This package contains
functions custom made to help facilitate the processing of campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_current_gh("irworkshop/campfin")
pacman::p_load(
  rvest, # used to scrape website and get html elements
  tidyverse, # data manipulation
  stringdist, # calculate distances between strings
  lubridate, # datetime strings
  magrittr, # pipe opperators
  janitor, # dataframe clean
  refinr, # cluster and merge
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  httr, # http queries
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here}
# where does this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Data

The data is obtained from the North Carolina Secretary of State's office [Lobbying Download webpage][03]. From there, we
can download the database for all terms including resigned lobbyists in a a rich text file. We'll make a
`httr::GET()` request on the file to download and write the text file to disk.

[03]:https://www.sosnc.gov/online_services/lobbying/download

Accoding to the North Carolina Secretary of State's office website, 
> 
                                             Lobbying is the influencing
                                                or attempting to influence legislative or executive branch action.  Lobbyists, lobbyist principals, state and local liaisons
                                                (those representing state and local governments), must register annually to lobby certain elected and appointed governmental officials.
                                                All must report quarterly and all of this information is accessible in our Directory.
                                            

```{r raw_get}
raw_dir <- here("nc", "lobby", "data", "raw")
dir_create(raw_dir)

lob_relative_url <- read_html("https://www.sosnc.gov/online_services/lobbying/lobbying_download_results") %>% html_nodes(xpath="//a[contains(text(),'Click Here To Download Text Only')]") %>% html_attr("href")

lob_url <- str_replace(lob_relative_url, "../../", "https://www.sosnc.gov/")

lob_file <- "nc_lob_master_20.txt"

lob_path <- str_c(raw_dir, lob_file, sep = "/")
if (!this_file_new(lob_path)) {
  GET(lob_url, write_disk(lob_path, overwrite = TRUE))
  unzip(lob_path, exdir = raw_dir)
}
```


## Import
The rich text file doesn't specify its delimiter, but we can determine that the delimiter is tabs after a little bit of tinkering with `read_lines()`.

First, we will use `readr::read_delim()` to read the data frame of lobbyists. There will be some parsing errors resulting in the fact that every line except for the headers ended with an extraneous `\t`, which we can safely disregard.

```{r raw_read_lob}
nc_lob <- read_delim(dir_ls(raw_dir, regexp = "20.txt"),
    "\t", escape_double = FALSE, trim_ws = TRUE, col_types = cols(
      .default = col_character()
    )) %>% clean_names()
```


## Explore

```{r glimpse, echo=FALSE}
head(nc_lob)
tail(nc_lob)
glimpse(nc_lob)
```
#### Duplicates

As you'd expect, some columns are more distinct than others. In our original lobbyist and
organization tables, the respect `*_id` variables are 100% distinct, but lobbyists are repeated
for every client organization in our joined data frame.

```{r col_distinct}
nc_lob <- flag_dupes(nc_lob, dplyr::everything())
```

#### Missing
`r count_na(nc_lob$lobby_name)` lobbyists are missing names, `r count_na(nc_lob$lobby_city)` and `r count_na(nc_lob$prin_city)` we flag these instances with `campfin::flag_na()`

```{r col_missing}
col_stats(nc_lob, count_na)
nc_lob <- nc_lob %>% flag_na(lobby_name, lobby_city, prin_city)
```


## Wrangle

To improve the consistency and search ability of our accountability database, we will perform some
simple and **confident** manipulations to the original data and create new, normalized variables.

### Phone

We can use `campfin::normal_phone()` to convert the numeric phone numbers into an unambiguous
character format. This prevents the column from being read as a numeric variable.

```{r phone_norm}
nc_lob <- mutate_at(
  .tbl  = nc_lob,
  .vars = vars(ends_with("phone")),
  .funs = list(norm = normal_phone)
)
```

```{r phone_view, echo=FALSE}
nc_lob %>% 
  select(contains("phone")) %>% 
  distinct() %>% 
  sample_frac()
```

### Address

To normalize the street addresses, we will first `tidyr::unite()` each address column into a single
column and then pass that string to `campfin::normal_address()`.

```{r addr_unite_lob}
nc_lob <- nc_lob %>% 
  unite(
    starts_with("lobby_address"),
    col = "lobby_address_full",
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  mutate(
    lobby_address_norm = normal_address(
      address = lobby_address_full,
      abbs = usps_street,
      na_rep = TRUE
    )
  ) %>% 
  select(-ends_with("address_full"))
```

```{r addr_unite_org}
nc_lob <- nc_lob %>% 
  unite(
    starts_with("prin_addr"),
    col = "prin_address_full",
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  mutate(
    prin_addr_norm = normal_address(
      address = prin_address_full,
      abbs = usps_street,
      na_rep = TRUE
    )
  ) %>% 
  select(-ends_with("address_full"))
```

```{r}
nc_lob %>% 
  select(starts_with("lob_addr")) %>% 
  distinct() %>% 
  sample_frac()
```

### ZIP

Our database uses 5-digit ZIP codes, so we can pass the original postal code variables to 
`campfin::normal_zip()` to trim the strings and try and repair and broken formats.

```{r zip_norm}
nc_lob <- mutate_at(
  .tbl  = nc_lob,
  .vars = vars(ends_with("zip")),
  .funs = list(norm = normal_zip),
  na_rep = TRUE
)
```

```{r zip_view, echo=FALSE}
nc_lob %>% 
  select(contains("zip")) %>% 
  distinct() %>% 
  sample_frac() %>% 
  filter(lobby_zip %out% valid_zip | prin_zip  %out% valid_zip)
```

This makes out new ZIP variables very clean.

```{r zip_progress, echo=FALSE}
progress_table(
  nc_lob$lobby_zip,
  nc_lob$lobby_zip_norm,
  nc_lob$prin_zip,
  nc_lob$prin_zip_norm,
  compare = valid_zip
)
```

### State

This database contains a mix of full state names and 2-letter abbreviations; we can pass these
variables to `campfin::normal_state()` to try and convert them all the abbreviations.
After normalization, we can see all lobbyist states are valid with some principal states with invalid values.
We will manually correct them and substitute with `NA`.

```{r state_norm}
nc_lob <- mutate_at(
  .tbl  = nc_lob,
  .vars = vars(ends_with("state")),
  .funs = list(norm = normal_state),
  abbreviate = TRUE
)

prop_in(nc_lob$lobby_state_norm, valid_state, na.rm = T)
prop_in(nc_lob$prin_state_norm, valid_state, na.rm = T)

nc_lob <- nc_lob %>% 
  mutate_at(
    .vars = vars(ends_with("state_norm")),
    .funs = na_if, "XX" 
  ) %>% 
  mutate(prin_state_norm = prin_state_norm %>% na_if("XX") %>% str_replace("LO", "LA"))
```

```{r state_view, echo=FALSE}
nc_lob %>% 
  select(contains("state")) %>% 
  distinct() %>% 
  sample_frac()
```

```{r state_progress, echo=FALSE}
progress_table(
  nc_lob$lobby_state,
  nc_lob$lobby_state_norm,
  nc_lob$prin_state,
  nc_lob$prin_state_norm,
  compare = valid_state
)
```

### City

#### Normalize
The city values are typically the hardest to normalize due to the variety of valid formats. Again,
the `campfin::normal_city()` function reduces inconsistencies and removes invalid values.

```{r city_norm}
nc_lob <- mutate_at(
  .tbl  = nc_lob,
  .vars = vars(ends_with("city")),
  .funs = list(norm = normal_city),
  abbs = usps_city,
  states = usps_state,
  na = invalid_city,
  na_rep = TRUE
)
```
#### Swap
Then, we can compare these normalized values to the _expected_ values for that record's ZIP code.
If the two values are similar, we can confidently assume a typo was made and default to the
expected value.

```{r swap_city_org}
nc_lob <- nc_lob %>% 
  left_join(
    y = zipcodes,
    by = c(
      "prin_state_norm" = "state",
      "prin_zip_norm" = "zip"
    )
  ) %>% 
  rename(prin_city_match = city) %>% 
  mutate(
    prin_match_abb = is_abbrev(prin_city_norm, prin_city_match),
    prin_match_dist = str_dist(prin_city_norm, prin_city_match),
    prin_city_swap = if_else(
      #condition = !is.na(prin_match_dist) & prin_match_abb | prin_match_dist == 1,
      condition = prin_match_abb | prin_match_dist == 1 & !is.na(prin_match_dist),
      true = prin_city_match,
      false = prin_city_norm
    )
  ) %>% 
  select(
    -prin_city_match,
    -prin_match_abb,
    -prin_match_dist
  )
```

Our relatively few city values were already very clean, but this process was able to make some
quick and easy improvements.

```{r city_progress, echo=FALSE}
progress_table(
  str_to_upper(nc_lob$lobby_city),
  nc_lob$lobby_city_norm,
  str_to_upper(nc_lob$prin_city),
  nc_lob$prin_city_norm,
  nc_lob$prin_city_swap,
  compare = c(valid_city, extra_city)
)
```

Now we can remove the normalized city column in favor of our improved compared value.

```{r city_rename}
nc_lob <- nc_lob %>% 
  select(-prin_city_norm) %>% 
  rename(prin_city_norm = prin_city_swap)
```

#### Check

```{r check, eval=FALSE}
api_key <- Sys.getenv("GEOCODING_API")

valid_place <-  c(valid_city, extra_city) %>% unique()

nc_check <- nc_lob %>% 
  filter(prin_city_norm %out% valid_place) %>% 
  drop_na(prin_city_norm, prin_state_norm) %>% 
  count(prin_city_norm, prin_state_norm)

nc_check_result <- 
  pmap_dfr(.l = list(city = nc_check$prin_city_norm, state = nc_check$prin_state_norm), 
           .f = check_city, 
           key = api_key, 
           guess = T)

nc_check <- nc_check %>% 
  left_join(nc_check_result %>% 
              select(-original_zip), 
            by = c("prin_city_norm" = "original_city", 
                   "prin_state_norm" = "original_state"))
```

```{r write check_table to csv, echo=FALSE, eval=FALSE}
clean_dir <- here("nc", "lobby", "data", "processed")
dir_create(clean_dir)
nc_check %>% write_csv(
    path = file.path(clean_dir,"nc_check.csv"),
    na = ""
  )
```

```{r read saved check_table, echo=FALSE}
clean_dir <- here("nc", "lobby", "data", "processed")
nc_check <- read_csv(glue("{clean_dir}/nc_check.csv"))
head(nc_check)
```

```{r check_join}
nc_check <- nc_check %>% 
  mutate(string_dist = stringdist(guess_place, prin_city_norm)) %>% 
  mutate(check_swap = if_else(condition = string_dist > 2,
                              true = prin_city_norm,
                              false = guess_place)) %>% 
  select(-string_dist)
```
If the string distances between `guess_place` and `prin_city_norm` is no more than two characters, we can make a confident swap to use the `guess_place` results in the new column named `check_swap`.
```{r}
nc_lob <- nc_check %>% select(prin_city_norm, prin_state_norm, check_swap) %>% 
  right_join(nc_lob, by = c("prin_city_norm", "prin_state_norm")) %>% 
  mutate(prin_city_clean = coalesce(check_swap, prin_city_norm)) %>% 
  select(-check_swap)

nc_lob <- nc_lob %>% 
  mutate(prin_city_clean = prin_city_clean %>% str_replace("RTP", "RESEARCH TRIANGLE PARK"))
```

```{r add to extra_city df, eval=FALSE}
extra_city_df <- gs_title("extra_city")

extra_city_df <- extra_city_df %>% 
  gs_add_row(ws = 1, input = nc_check %>% filter(check_city_flag) %>% select(guess_place))
```

```{r progress table}
valid_place <- c(valid_city, extra_city) %>% unique()

valid_place <-  c(valid_place,"RESEARCH TRIANGLE PARK",
                  nc_check$prin_city_norm[nc_check$check_city_flag]) %>% unique() 

progress_table(
  nc_lob$prin_city,
  nc_lob$prin_city_norm,
  nc_lob$prin_city_clean,
  compare = valid_place
)
```

## Export
```{r prepare_export}
nc_lob <- nc_lob %>% 
  rename(prin_zip5 = prin_zip_norm,
         lobby_zip5 = lobby_zip_norm,
         lobby_state_clean = lobby_state_norm,
         prin_state_clean = prin_state_norm,
         lobby_city_clean = lobby_city_norm)
```


```{r proc_dir}
proc_dir <- here("nc", "lobby", "data", "processed")
dir_create(proc_dir)
```

```{r proc_write}
write_csv(
  x = nc_lob %>% select(-prin_city_norm),
  path = glue("{proc_dir}/nc_lobby_reg_clean.csv"),
  na = ""
)
```

