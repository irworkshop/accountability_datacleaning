---
title: "Wyoming Contracts"
author: "Kiernan Nicholls"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
if (!interactive()) {
  options(width = 99)
  set.seed(5)
}
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
doc_dir <- fs::dir_create(here::here("wy", "contracts", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give
journalists, policy professionals, activists, and the public at large a simple
way to search across huge volumes of public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each
dataset row as a transaction. For each transaction there should be (at least) 3
variables:

1. All **parties** to a transaction.
2. The **date** of the transaction.
3. The **amount** of money involved.

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for entirely duplicated records.
1. Check ranges of continuous variables.
1. Is there anything blank or missing?
1. Check for consistency issues.
1. Create a five-digit ZIP Code called `zip`.
1. Create a `year` field from the transaction date.
1. Make sure there is data on both parties to a transaction.

## Packages

The following packages are needed to collect, manipulate, visualize, analyze,
and communicate these results. The `pacman` package will facilitate their
installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This
package contains functions custom made to help facilitate the processing of
campaign finance data.

```{r load_packages, message=FALSE, warning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load(
  tidyverse, # data manipulation
  lubridate, # datetime strings
  gluedown, # printing markdown
  magrittr, # pipe operators
  janitor, # clean data frames
  refinr, # cluster and merge
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  rvest, # html scraping
  glue, # combine strings
  here, # relative paths
  httr, # http requests
  fs # local storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a
sub-directory of the more general, language-agnostic
[`irworkshop/accountability_datacleaning`][tap] GitHub repository.

The `R_campfin` project uses the [RStudio projects][rproj] feature and should be
run as such. The project also uses the dynamic `here::here()` tool for file
paths relative to _your_ machine.

```{r where_here}
# where does this document knit?
here::here()
```

[tap]: https://github.com/irworkshop/accountability_datacleaning
[rproj]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects

## Data

Wyoming vendor payments can be obtained from the [WyOpen portal][wyo], which is
run by the [Wyoming State Auditor's Office][sao].

> #### Welcome
> WyOpen gives you easy access to State of Wyoming expenditures, so you can see
how our state spends money. This site includes payments made by the State of
Wyoming through the Wyoming Online Financial System (WOLFS) to vendors for the
purchase of goods and services.
>
> Currently, this site includes expenditure data or expenditures made by the
State of Wyoming between January 5th 2016 through July 2nd 2020. 

> #### Checkbook Data
> Quarterly updates will typically be available 30 days after quarter end. For
example, data for January, February and March will be uploaded and made
available by April 30th.

> #### Completeness
> The data presented on this website does not include all State of Wyoming
expenditures. Confidential or sensitive data protected by state or federal law
has been excluded. Information excluded may include, but is not limited to:
* Transactions that qualify as “Aid to Individuals” (e.g., Medicaid, Medicare)
* Refunds associated with assistance programs
* Expenses related to confidential law enforcement activities
* Subsidized adoptions; and/or foster care payments
* Child support recoveries collections, distributions and refunds
* Victim compensation claims
* Personnel and disability payment claims

> #### Limitations
> Individual agency expenditures may not align with the agency’s final
appropriated budget due to the removal of confidential payments and/or timing of
expenditures and encumbrances.

[wyo]: http://www.wyopen.gov/
[sao]: https://sao.wyo.gov/

## Download

We can use the [WyOpen advance search portal][adv] functionality to return all
records between two dates and export them directly as a CSV text file.

The earliest date for data is 01/05/2016 and the latest Date is 07/02/2020.
However, if we just use those two dates we get search results for 3,612,722
payment records but trying to export those results as a CSV text file produces
an error every time:

> The requested URL was rejected. Please consult with your administrator.

To circumvent this problem, we are going to use the `httr::POST()` and 
`httr::GET()` functions to automate searches for every month and download
those monthly results locally.

[adv]: http://www.wyopen.gov/search/advanced

```{r raw_dir}
raw_dir <- dir_create(here("wy", "contracts", "data", "raw"))
```

The process to download files comes in three steps:

1. `POST()` the form with our `startdate` and `enddate`.
2. Note the `cookies()` the WyOpen server gives from that `POST()`.
3. `GET()` the CSV text file containing the returned form results.

We can create a vector of month starts between our earliest and latest days.

```{r raw_months, results='asis'}
month_starts <- seq(
  from = mdy("01/01/2016"), 
  to = today() - days(1), 
  by = "month"
)
```

Then we loop through these months, setting that beginning of the month
as the start date and the last day of the month as the end.

```{r raw_download}
if (length(dir_ls(raw_dir)) == 0) {
  for (day in month_starts) {
    day <- as_date(day)
    # search between days in month
    month_post <- POST(
      url = "http://www.wyopen.gov/search/advancedsearch",
      body = list(
        startdate = format(day, "%m/%d/%Y"),
        enddate = format(day + months(1) - days(1), "%m/%d/%Y"),
        agencyid = "",
        objectid = "",
        subobjectid = "",
        vendorname = "",
        location = "",
        MySubmit = "Search"
      )
    )
    # convert cookies to named vector
    wy_cookies <- cookies(month_post)$value
    names(wy_cookies) <- cookies(month_post)$name
    # define file name by year and month
    file_name <- glue("SearchResults-{str_sub(day, end = 7)}.csv")
    # write results as CSV locally
    GET(
      url = "http://www.wyopen.gov/search/csv",
      write_disk(path(raw_dir, file_name)),
      set_cookies(wy_cookies)
    )
    message(day)
    Sys.sleep(10)
  }
}
```

```{r raw_info}
raw_info <- dir_info(raw_dir)
as_tibble(raw_info) %>% 
  select(path, size, modification_time) %>% 
  mutate(across(path, path.abbrev))
```

## Read

```{r raw_read}
wyc <- vroom(
  file = raw_info$path,
  num_threads = 1,
  escape_double = FALSE,
  escape_backslash = FALSE,
  col_types = cols(
    .default = col_character(),
    doccreatedt = col_date(),
    lineamount = col_double()
  )
)
```

```{r raw_rename}
wyc <- wyc %>%
  rename(
    date = doccreatedt,
    amount = lineamount
  )
```

## Explore

```{r glimpse}
glimpse(wyc)
tail(wyc)
```

### Missing

```{r na_count}
col_stats(wyc, count_na)
```

### Duplicates

```{r dupe_flag}
d1 <- duplicated(wyc, fromLast = FALSE)
d2 <- duplicated(wyc, fromLast = TRUE)
wyc <- mutate(wyc, dupe_flag = d1 | d2)
sum(wyc$dupe_flag)
rm(d1, d2); flush_memory()
```

```{r dupe_view}
wyc %>% 
  filter(dupe_flag) %>% 
  select(date, agency, amount, vendor)
```

### Categorical

```{r distinct_count}
col_stats(wyc, n_distinct)
```

```{r distinct_plots}
explore_plot(wyc, agency) + scale_x_truncate()
```

### Amounts

```{r amount_summary}
summary(wyc$amount)
mean(wyc$amount <= 0)
```

```{r amount_max}
glimpse(wyc[which.max(wyc$amount), ])
```

```{r hist_amount, echo=FALSE}
wyc %>%
  ggplot(aes(amount)) +
  geom_histogram(fill = dark2["purple"]) +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(
    breaks = c(1 %o% 10^(0:6)),
    labels = dollar,
    trans = "log10"
  ) +
  labs(
    title = "Wyoming Contracts Amount Distribution",
    caption = "Source: WyOpen",
    x = "Amount",
    y = "Count"
  )
```

### Dates

We can add the calendar year from `date` with `lubridate::year()`

```{r date_year}
wyc <- mutate(wyc, year = year(date))
```

```{r date_range}
min(wyc$date)
sum(wyc$year < 2000)
max(wyc$date)
sum(wyc$date > today())
```

```{r bar_year, echo=FALSE}
wyc %>% 
  count(year) %>% 
  mutate(even = is_even(year)) %>% 
  ggplot(aes(x = year, y = n)) +
  geom_col(aes(fill = even)) + 
  scale_fill_brewer(palette = "Dark2") +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(breaks = 2016:2020) +
  theme(legend.position = "bottom") +
  labs(
    title = "Wyoming Contracts by Year",
    caption = "Source: WyOpen",
    fill = "Election Year",
    x = "Year Made",
    y = "Count"
  )
```

## Wrangle

```{r state_check}
prop_in(wyc$state, valid_state)
```

```{r strate_add}
wyc <- mutate(wyc, agency_state = "WY", .after = agency)
```

## Conclude

Before exporting, we can remove the intermediary normalization columns and
rename all added variables with the `_clean` suffix.

```{r clean_glimpse}
glimpse(sample_n(wyc, 100))
```

1. There are `r comma(nrow(wyc))` records in the database.
1. There are `r comma(sum(wyc$dupe_flag))` duplicate records in the database.
1. The range and distribution of `amount` and `date` seem reasonable.
1. There are `r comma(sum(wyc$na_flag))` records missing key variables.
1. Consistency in geographic data has been improved with `campfin::normal_*()`.
1. The 4-digit `year` variable has been created with `lubridate::year()`.

## Export

Now the file can be saved on disk for upload to the Accountability server.

```{r clean_dir}
clean_dir <- dir_create(here("wy", "contracts", "data", "clean"))
clean_path <- path(clean_dir, "wy_contracts_clean.csv")
write_csv(wyc, clean_path, na = "")
file_size(clean_path)
file_encoding(clean_path) %>% 
  mutate(across(path, path.abbrev))
```

## Upload

Using the [duckr] R package, we can wrap around the [duck] command line tool to
upload the file to the IRW server.

[duckr]: https://github.com/kiernann/duckr
[duck]: https://duck.sh/

```{r clean_upload, eval=FALSE}
# remotes::install_github("kiernann/duckr")
s3_dir <- "s3:/publicaccountability/csv/"
s3_path <- path(s3_dir, basename(clean_path))
if (require(duckr)) {
  duckr::duck_upload(clean_path, s3_path)
}
```

## Dictionary

The following table describes the variables in our final exported file:

```{r dict_make, echo=FALSE}
dict_raw <- tibble(
  var = md_code(names(wyc)),
  type = md_code(map_chr(wyc, typeof)),
  def = c(
    "Unique transaction ID",
    "Spending agency name",
    "Spending agency state",
    "Recieving vendor",
    "Object purchased",
    "Purchase details",
    "Date payment made",
    "Vendor state",
    "Payment amount",
    "Flag indicatting duplicate record",
    "Year made"
  )
)
```

```{r dict_md, echo=FALSE}
(dict_md <- kable(
  x = dict_raw,
  format = "markdown",
  col.names = c("Column", "Type", "Definition")
))
```
