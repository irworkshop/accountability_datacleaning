---
title: "Nevada Lobbying Registration Data Diary"
author: "Yanqi Xu"
date: "`r format(Sys.time())`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

## Project


The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.


Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:


1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved


## Objectives


This document describes the process used to complete the following objectives:


1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction


## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

```{r p_load, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_current_gh("irworkshop/campfin")
pacman::p_load(
  rvest, # read html tables
  httr, # interact with http requests
  stringdist, # levenshtein value
  tidyverse, # data manipulation
  lubridate, # datetime strings
  tidytext, # string analysis
  magrittr, # pipe opperators
  janitor, # dataframe clean
  refinr, # cluster and merge
  knitr, # knit documents
  glue, # combine strings
  scales, #format strings
  here, # relative storage
  fs, # search storage 
  vroom, #read deliminated files
  readxl, #read excel files
  pdftools #wrangle pdf texts
)
```

```{r fix_fun, echo=FALSE, collapse = TRUE}
# fix conflict
here <- here::here
print_all <- function(df) df %>% print(n = nrow(.)) 
```
This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.


The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.


## Download
Set the download directory first.
```{r create raw_dir}
# create a directory for the raw data
doc_dir <- here("nv", "lobby", "docs")

raw_dir <- here("nv", "lobby", "data", "raw","reg")

dir_create(c(raw_dir, doc_dir))
```
According to [CT Office of State Ethics] [03], 

> Lobbying in Connecticut is defined as "communicating directly or soliciting others to communicate with any official or his or her staff in the legislative or executive branch of government or in a quasi-public agency, for the purpose of influencing any legislative or administrative action."

Lobbyist terms:  
> A Client Lobbyist is the party paying for lobbying services on its behalf. In other words, the client lobbyist is expending or agreeing to expend the threshold amount of $3,000 in a calendar year. A Communicator Lobbyist receives payment and does the actual lobbying legwork (i.e., communicating or soliciting others to communicate).  
> A Communicator Lobbyist receives or agrees to receive $3,000 for lobbying activities in a calendar year. A communicator lobbyist can be:  
 	1.	An individual; or
 	2.	A member of a Business Organization (e.g., a firm or association that is owned by or employs a number of lobbyists), Conn. Gen. Stat. § 1-91 (t); or
 	3.	An In-house Communicator (a lobbyist who is a salaried employee of a client lobbyist).

Registration and Filing Specifics:

> Individuals or entities are required by law to register as a lobbyist with the Office of State Ethics (OSE) if they:  
 	1.	Expend or agree to expend $3,000 or more in a calendar year in lobbying; OR
 	2.	Receive or agree to receive $3,000 or more in a calendar year in lobbying.
 	Once the $3,000 threshold is met, registration with the OSE is required. Registration occurs biennially (every two years) by January 15, or prior to the commencement of lobbying, whichever is later.
	
Client Lobbyists:  
 	> 1.	Client lobbyists file quarterly financial reports, with the third and fourth quarters combined. These reports are filed between the 1st and 10th days of April, July and January.  
 	2.	To ensure timely transparency, if a client lobbyist spends or agrees to spend more than $100 in legislative lobbying while the Legislature is in regular session, that lobbyist must file monthly financial reports.  
 	3.	The quarterly and monthly reports gather information such as compensation, sales tax and money expended in connection with lobbying; expenditures benefiting a public official or his/her staff or immediate family; all other lobbying expenditures; and the fundamental terms of any lobbying contract or agreement.
	
Communicator Lobbyists:  
 	> Communicator lobbyists also register upon meeting the threshold amount. Communicator lobbyists generally file a financial report once a year, due by January 10. These reports capture compensation, reimbursements from the client lobbyist and sales tax for the previous year.  
 	If a communicator lobbyist makes unreimbursed expenditures of $10 or more for the benefit of a public official, a member of his/her staff, or his/her immediate family, that lobbyist must also file on the client lobbyists schedule (either monthly or quarterly).

[03]: https://www.oseapps.ct.gov/NewLobbyist/PublicReports/LobbyistFAQ.aspx
This Rmd file documents the CT registration data only, whereas the expenditure data is wrangled in a separate data diary.


To generate a master dataset, we will need to download four kinds of data tables from [Office of State Ethics](https://www.oseapps.ct.gov/NewLobbyist/PublicReports/AdditionalReports.aspx), _Communicator Lobbyist List_ for information about lobbyists, _All Registrants - Client_ for information about clients, _Registration by Client, Communicator, Bus Org and Registration Date_ for their relationships, as well as the _Combined Lobbyist List by Registrant with Type of Lobbying and Issues_. There will be overlapping and missing fields, but we will use the _Registration by Client, Communicator, Bus Org and Registration Date_  as the base table since it captures the relationship between the lobbyists and their clients.

## Scrape
We will use `rvest` to scrape the website. The Nevada State Legislature site makes available all registry from year 2013 to year 2019.
```{r download}
nv_80 <- html('https://www.leg.state.nv.us/Lobbyist/80th2019/Lobbyist?lobbyist-grid-pageSize=10000')

table <- nv_80 %>% html_nodes('table')

parsetb <- table[[2]] %>% html_table()

parsetb <- parsetb %>% 
  rename(lob = X1, client = X2)

#table <- nv_80 %>% html_nodes('.first-column-container')
table_text <- table %>% html_text() %>% map(read_lines)

for (i in seq_along(table_text)) {
  names = table_text[[i]][7]
    return(names)
}
```


```{r}
type_regex <- "Paid Lobbyist|Non-Paid Lobbyist|Non-Paid Military Veteran Lobbyist|Unknown Lobbyist|Paid Non-Profit Lobbyist|Non-Paid"

parsetb <- parsetb %>% 
  mutate(lob = str_remove(lob,"Photo not available"),
           lob_type = lob %>% str_extract(type_regex),
         revoke_status = lob %>% str_extract("Revoked\\s\\d*\\/\\d*\\/\\d{4}"),
          lob_name = {lob %>% str_remove("Revoked\\s\\d*\\/\\d*\\/\\d{4}") %>% str_replace(type_regex, "`") %>% str_match("(^\\D*)`")}[,2] %>% trimws(),
         lob_address = lob %>% str_remove("Revoked\\s\\d*\\/\\d*\\/\\d{4}") %>% str_remove(lob_name) %>% str_replace(type_regex, "`") %>% str_remove("(^\\D*)`") %>% trimws())
```

### PDF
```{r}
nv_17_lines <- pdf_text(glue("{raw_dir}/reg_17.pdf")) %>% read_lines()
breaks <- which(nv_17_lines == "")
invalid_posit <- c(breaks-1,breaks, breaks+1, breaks+2, breaks+3, breaks+4)

nv_17_valid <- nv_17_lines[setdiff(3:{length(nv_17_lines)-1}, invalid_posit)]

nv_17_sep <- nv_17_valid %>% str_split("\\s{4,}")
for (i in seq_along(nv_17_sep)){
 x <-  nv_17_sep[i]
#filter out the empty ""
   x <- x[[1]][x[[1]] != ""]
 nv_17_sep[[i]] <- x
}

line_count <-  nv_17_sep %>% map_dbl(length) 

# since the end of a lobbyist line will only has length 1, and the next line will have length 2 where the client name is the second element, we'll use this characteristic to identify the separator of these lines
sep <- double()
for (i in seq_along(line_count)) {
  # find out the index of element 1 immediately followed by a 2, that will be the index of the last line of 
  if (line_count[i] == 1 & line_count[i+1] == 2) {
    #
    sep <- append(sep, i)
  }
}

start_index <- c(1, (sep+1))

tibs <- list(NA) %>% rep(length(start_index))
for (i in seq_along(start_index)){
  if (i == length(start_index)) {
    single_index <- start_index[i]:length(nv_17_sep)
  }else{
  single_index <- start_index[i]:(start_index[i+1]-1)
  }
  single_lines_list <- nv_17_sep[single_index]
      lob <- rep(NA, length(single_index))
      cl <- rep(NA, length(single_index))
  for (j in seq_along(single_index))  {
    lob[j] <- single_lines_list[[j]][1]
    cl[j] <- single_lines_list[[j]][2]
    tibs[[i]] <- tibble(lobbyist = lob %>% str_c(collapse = '`'),
                  client = cl %>% na.omit() %>% str_c(collapse = "`"))
  }
}

```


#### Name
We will replace the fields that said `1` for `communicator_name` and `comm_type` in `nv_reg`.
```{r full name}
nv_reg <- nv_reg %>% mutate(communicator_status = str_match(communicator_name, " [(]TERMINATED: .+[)]") %>% 
                              str_remove("[(]") %>% str_remove("[)]"),
                            communicator_name_clean = str_remove(communicator_name,  " [(]TERMINATED: .+[)]"),
                            communicator_status = communicator_status %>% trimws())

nv_reg <- nv_reg %>% 
  mutate(first_name = str_match(communicator_name_clean, ",(.[^,]+$)")[,2],
         last_name = str_remove(communicator_name_clean, str_c(",",first_name)))

nv_reg <- nv_reg %>% 
  mutate(comm_type = na_if(x = comm_type, y = "1"),
         communicator_name = na_if(x = communicator_name, y = "1"))
```

## Explore

### Duplicates

We'll use the `flag_dupes()` function to see if there are records identical to one another and flag the duplicates. A new variable `dupe_flag` will be created.

```{r flag dupe}
ct_lob <- flag_dupes(ct_lob, dplyr::everything())
ct_cl <- flag_dupes(ct_cl, dplyr::everything())
nv_reg <- flag_dupes(nv_reg, dplyr::everything())
```


```{r }
nv_reg %>% 
  group_by(year) %>% 
  ggplot(aes(year)) +
  scale_x_continuous(breaks = 2013:2019) +
  geom_bar(fill = RColorBrewer::brewer.pal(3, "Dark2")[1]) +
  labs(
    title = "Connecticut Lobbyists Registration by Year",
    caption = "Source: CT Office of State Ethics",
    x = "Year",
    y = "Count"
  )
```

### Missing
There's almost no empty fields in the two data frames. 
```{r count_na}
ct_lob  %>% col_stats(count_na)
ct_cl  %>% col_stats(count_na)
```
Few values are missing from the lobbyists database.

## Wrangling
We'll wrangle the two datasets to extract information such as address, city, ZIP, state, phone for both lobbyists and their clients, as well as authorization date. The lobbyists registry has the one-to-one relationship between lobbyists and clients, so we will use `ct_cl` as the main data frame and join the clients' information from the `ct_lob` data frame.

### ZIP 
The ZIP code fields are pretty clean.
```{r client normal zip}
parsetb <- parsetb %>% 
  mutate(lob_zip = str_match(lob_address, "\\d{5}"))
prop_in(ct_cl$zip, valid_zip, na.rm = TRUE) %>% percent()
prop_in(ct_lob$zip, valid_zip, na.rm = TRUE) %>% percent()
```



### Phone
```{r normal phone}
nv_80 <- ct_cl %>% mutate(phone_norm = normal_phone(phone))
ct_cl  <- ct_cl  %>% mutate(phone_norm = normal_phone(phone))
```
### State
Running the following commands tells us the state fields are clean. The fields that are `NA`s were missing from the original field. 
```{r clients clean state}
st_regex <- paste(valid_state, collapse = " | ")

parsetb <- parsetb %>% 
  mutate(lob_state = lob_address %>% str_extract(st_regex) %>% trimws())

prop_in(parsetb$lob_state, valid_state, na.rm = TRUE) %>% percent()
```

### Address
Running the following command, we'll see that for row #787, the address field is missing, hence the actual city-filled address field, and a empty city field. We will manuall change it.
```{r normal address}
#split address_full strings using greedy regex match
parsetb <- parsetb %>% 
  mutate(lob_add_city = lob_address %>% str_remove(",\\s([A-Z]{2})\\s\\d{5}.*$")) %>% 
  separate(col = lob_add_city, sep = "\r\n", into = c('lob_address_only', "lob_city"))

parsetb$lob_address_only[787] <- NA_character_
parsetb$lob_city[787] <- "Reno"
```

### Client Fields
With clients, we will need to separate the multiple clients nested in the same column first.
```{r}
variable <- parsetb$client
each_lob <- list(NA) %>% rep(length(variable))
for (i in seq_along(variable)) {
  if (variable[i] == "") {
  next()
}
client_all <- variable[i] %>% read_lines()

num_client <- (length(client_all) +1)/6
      tibs <- list(NA) %>% rep(num_client)
  for (j in 1:num_client) {
single_line <- client_all[(6*j-5):(6*j-1)]
    tibs[[j]] <- tibble(client_name = single_line[1],
                  client_phone = single_line[2],
                  client_address = single_line[3],
                  client_citystate = single_line[4],
                  client_zip = single_line[5])
  }
  # if (length(tibs)>1) {
    each_lob_temp <- bind_rows(tibs)
  # }else{
  #   each_lob_temp <- tibs
  # }
    each_lob[[i]] <- data_frame(parsetb[i,]) %>% rep(num_client) %>% bind_rows() %>% cbind(each_lob_temp) 
  }


nv_80 <- each_lob %>% map_dfr(as_tibble) %>% 
  mutate_if(is_character, ~str_trim(str_squish(.)))

```

### City
The city fields in both data frames use upper-case letters and lower-case letters inconsistently. We'll convert everything to upper case.
```{r}
prop_in(ct_cl$city, valid_city, na.rm = TRUE) %>% percent()
prop_in(ct_lob$city, valid_city, na.rm = TRUE) %>% percent()
```

#### Normalize
```{r lb norm_city, collapse = TRUE}
ct_cl <- ct_cl %>% mutate(city_norm = normal_city(city = city,
                                            abbs = usps_city,
                                            states = c(valid_state),
                                            na = invalid_city,
                                            na_rep = TRUE))
n_distinct(ct_cl$city)
n_distinct(ct_cl$city_norm)

prop_in(ct_cl$city, valid_city, na.rm = TRUE)
prop_in(ct_cl$city_norm, valid_city, na.rm = TRUE)
```

```{r cl norm_city, collapse = TRUE}
ct_lob <- ct_lob %>% mutate(city_norm = normal_city(city = city,
                                            abbs = usps_city,
                                            states = c(valid_state),
                                            na = invalid_city,
                                            na_rep = TRUE))
n_distinct(ct_lob$city)
n_distinct(ct_lob$city_norm)

prop_in(ct_lob$city, valid_city, na.rm = TRUE)
prop_in(ct_lob$city_norm, valid_city, na.rm = TRUE)
```

#### Swap
Then, we will compare these normalized `city_norm` values to the _expected_ city value for that
vendor's ZIP code. If the [levenshtein distance][09] is less than 3, we can confidently swap these
two values.

[09]: https://en.wikipedia.org/wiki/Levenshtein_distance

```{r cl swap_city}
ct_lob <- ct_lob %>% 
  left_join(
    y = zipcodes,
    by = c(
      "state" = "state",
      "zip" = "zip"
    )
  ) %>% 
  rename(city_match = city.y,
         city = city.x) %>% 
  mutate(
    match_abb = is_abbrev(city_norm, city_match),
    match_dist = str_dist(city_norm, city_match),
    city_swap = if_else(
      condition = match_abb | match_dist == 1,
      true = city_match,
      false = city_norm
    )
  ) %>% 
  select(
    -city_match,
    -match_dist,
    -match_abb
  )

prop_in(ct_lob$city_swap, valid_city, na.rm = TRUE) %>% percent()
```

```{r lb swap_city}
ct_cl <- ct_cl %>% 
  left_join(
    y = zipcodes,
    by = c(
      "state" = "state",
      "zip" = "zip"
    )
  ) %>% 
  rename(city_match = city.y,
         city = city.x) %>% 
  mutate(
    match_abb = is_abbrev(city_norm, city_match),
    match_dist = str_dist(city_norm, city_match),
    city_swap = if_else(
      condition = match_abb | match_dist == 1,
      true = city_match,
      false = city_norm
    )
  ) %>% 
  select(
    -city_match,
    -match_dist,
    -match_abb
  )

prop_in(ct_cl$city_swap, valid_city, na.rm = TRUE) %>% percent()
```

Besides the `valid_city` vector, there is another vector of `extra_city` that contains other locales. We'll incorporate that in our comparison.

```{r valid_place check, echo=FALSE}
valid_place <- c(valid_city, extra_city) %>% unique()

progress_table(
  ct_lob$city,
  ct_lob$city_norm,
  ct_lob$city_swap,
  compare = valid_place
)

progress_table(
  ct_cl$city,
  ct_cl$city_norm,
  ct_cl$city_swap,
  compare = valid_place
)
```

This is a very fast way to increase the valid proportion in the lobbyist data frame to
`r percent(prop_in(ct_cl$city_swap, extra_city, na.rm = TRUE))` and reduce the number of distinct
_invalid_ values from `r length(setdiff(ct_cl$city_norm, valid_place))` to only
`r length(setdiff(ct_cl$city_swap, valid_place))`

Similarly, the valid proportion in the  clients data frame  was bumped up to
`r percent(prop_in(ct_lob$city_swap, extra_city, na.rm = TRUE))` and reduce the number of distinct
_invalid_ values from `r length(setdiff(ct_lob$city_norm, valid_place))` to only
`r length(setdiff(ct_lob$city_swap, valid_place))`

## Join
We'll join the two data frames together. Since there're no duplicate columns, we will delete the `dupe_flag` columns and add suffixes to each dataset's column names.
```{r join pre}
ct_cl$dupe_flag %>% tabyl()
ct_lob$dupe_flag %>% tabyl()

ct_lob <- ct_lob %>% 
  filter(!dupe_flag) %>% 
  select(-c(dupe_flag,
            city_norm)) %>% 
  rename(city_clean = city_swap) %>% 
  rename_all(.funs = ~str_c("lobbyist_",.))

ct_cl <- ct_cl %>% 
  select(-c(city_norm, dupe_flag)) %>% 
  rename(city_clean = city_swap) %>% 
  rename_at(.vars = vars(-starts_with("client_"))
            ,.funs = ~ str_c("client_", .))

ct_cl <- ct_cl %>% flag_dupes(client_name, client_registration_date)
ct_lob <- ct_lob %>% flag_dupes(lobbyist_first_name, lobbyist_last_name, lobbyist_year, lobbyist_organisation_name)
```
After the join, we can see that all the clients' id information is accounted for. After the join, we can see the total numbers of NA columns are consistent, and we are not introducting extraneous entries. The numbers of NA columns are also consistent. 
```{r join}
nv_reg <- nv_reg %>% select(-dupe_flag)

nv_reg <- ct_cl %>% 
  filter(!dupe_flag) %>% 
  right_join(nv_reg,
            by = c("client_name" = "client_name",
            "client_registration_date" = "registration_date"))

col_stats(nv_reg, count_na)

nv_reg <- ct_lob %>% 
  filter(!dupe_flag) %>% 
  select(-dupe_flag) %>% 
  right_join(nv_reg,
            by = c( 'lobbyist_last_name' ='last_name',
                    'lobbyist_first_name' ='first_name',
                   'lobbyist_year' = 'year',
                   'lobbyist_organisation_name' = "business_organization"))

col_stats(nv_reg, count_na)

head(nv_reg)
```


## Export

```{r write clean}
clean_dir <- here("ct", "lobby", "data", "processed","reg")
dir_create(clean_dir)
nv_reg %>% 
  select(-c(dupe_flag)) %>% 
  mutate_if(is.character, str_to_upper) %>% 
  write_csv(
    path = glue("{clean_dir}/ct_lobby_reg.csv"),
    na = ""
  )
```


