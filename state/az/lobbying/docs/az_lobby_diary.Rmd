---
title: "Arizona Lobbyists"
author: "Kiernan Nicholls"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
fs::dir_create(here::here("az", "lobby", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This package contains
functions custom made to help facilitate the processing of campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load_gh("kiernann/gluedown")
pacman::p_load(
  tidyverse, # data manipulation
  lubridate, # datetime strings
  magrittr, # pipe opperators
  janitor, # dataframe clean
  refinr, # cluster and merge
  scales, # format strings
  readxl, # read excel files
  knitr, # knit documents
  vroom, # read files fast
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here}
# where does this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Data

Data is obtained fromt the [Arizona Secretary of States](https://azsos.gov). The data was obtained
personally from a contanct at the SOS office. The data is only available publically in PDF format.

## Import

The data was provided to IRW as a `.zip` archives of 12 `.csv` files and one `.xlsx` file with a
key describing each of the individual files.

```{r raw_dir}
raw_dir <- here("az", "lobbying", "data", "raw")
dir_exists(raw_dir)
```

We can read the excel file with `readxl::read_excel()` and list the rows.

```{r keys_list, results='asis'}
here("az", "lobbying", "data", "raw", "LOB Database Key.xlsx") %>% 
  read_excel(col_names = FALSE) %>% 
  select(1) %>% 
  as_vector() %>% 
  unname() %>% 
  map_md(md_code, 1) %>% 
  md_bullet()
```

Then, we can `unzip()` the file and list the `.csv` files within.

```{r raw_unzip}
zip_file <- dir_ls(raw_dir, glob = "*.zip$")
unzip(
  zipfile = zip_file,
  exdir = raw_dir
)
```

```{r raw_list, results='asis'}
lob_dir <- dir_ls(raw_dir, type = "dir")
dir_ls(lob_dir) %>% 
  str_remove("^.*(az)") %>% 
  md_code() %>% 
  md_bullet()
```

We will join together these various tables into a single database of lobbyists, their employers,
and their clients. First, we will have to read each file.

The `LOB.csv` file contains the base information on each lobbyist (name, phone, address, etc).

```{r lob_read}
lob <- read_csv(
  file = str_c(lob_dir, "LOB.CSV", sep = "/"),
  col_types = cols(.default = col_character()),
)
```

```{r echo=FALSE}
n <- n_distinct(lob$LOB_ID)
lob <- clean_names(lob)
```

```{r echo=FALSE}
glimpse(sample_frac(lob))
```

The `LOG_REG.csv` file contains the information regarding each lobbyist's registration status for
_every_ term for which they were registered.

```{r reg_read}
lob_reg <- read_csv(
  file = str_c(lob_dir, "LOB_REG.CSV", sep = "/"),
  col_types = cols(
    .default = col_character(),
    LOB_TERM = col_integer(),
    REQUIRED = col_logical(),
    RECEIVED = col_date("%m/%d/%Y %H:%M %p"),
    STARTED = col_date("%m/%d/%Y %H:%M %p"),
    TERMINATED = col_date("%m/%d/%Y %H:%M %p")
  )
)
```

```{r echo=FALSE}
lob_reg <- clean_names(lob_reg)
```

```{r echo=FALSE}
sample_n(lob_reg, 10)
```

The `lob_reg` data frame can be joined with the base `lob` using the `lob_id` variable as a
relational key. When we perform a `dplyr::left_join()`, new rows will be created. In the `lob` data
frame, each lobbyist is only listed once. After joining, those single rows will be repeated with
new distinct rows from `lob_reg`.

```{r reg_join}
# lob <- left_join(lob, lob_reg, by = "lob_id")
```

The next data set to add will be the client (pincipal) represented by each lobbyist. The names of
each lobbist are contained in `PPB.csv` and their registration is included in `PPB_REG.csv`.

```{r ppb_read}
ppb <- read_csv(
  file = str_c(lob_dir, "PPB.CSV", sep = "/"),
  col_types = cols(
    .default = col_character(),
    PPB_REP.REP_YEAR = col_integer(),
    PPB_REP.REQUIRED = col_logical(),
    PPB_REP.EXEMPTED = col_logical(),
  )
)
```

```{r ppb_repair, echo=FALSE}
names(ppb) <- str_extract(string = names(ppb), pattern = "[^.]+$")
ppb <- ppb %>% 
  clean_names("snake") %>% 
  remove_empty("cols") %>% 
  filter(!is.na(ppb_name)) %>% 
  select(-required, -exempted)
```

```{r echo=FALSE}
sample_n(ppb, 10)
```

The `ppb` data frame can be linked to `lob` using the data in `REF.csv`.

```{r ref_read}
ref <- read_csv(
  file = str_c(lob_dir, "REF.CSV", sep = "/"),
  col_types = cols(
    .default = col_character(),
    DESIGNATED = col_logical(),
    STARTED = col_date("%m/%d/%Y %H:%M %p"),
    TERMINATED = col_date("%m/%d/%Y %H:%M %p"),
    COMPENSATED = col_logical()
  )
)
```

```{r echo=FALSE}
ref <- clean_names(ref)
```

Since each lobbyist in `lob` represents _multiple_ principals in `ppb`, when we join these list
together, some rows of `lob` will be duplicated aside from the unique `ppb_id`. Many of the
principals (IDs) listed in `ref` do not exist in `ppb` and would create useless empty rows when
joined to `lob` (along the `lob_id` in ref). We will filter out these rows.

```{r ref_join}
azl <- lob %>%
  # add all the principals of a lobbyist
  left_join(ref, by = "lob_id") %>% 
  # add the names of those principals
  left_join(ppb, by = "ppb_id")
```

```{r}
azl %>% 
  arrange(
    lob_lastname,
    desc(rep_year),
    ppb_name
  )
```

## Explore

After these various joins, our new data frame contains one row per client, per lobbyist, per year.

```{r glimpse}
azl %>% 
  select(
    lob_id,
    lob_lastname,
    ppb_id,
    ppb_name,
    rep_year
  ) %>% 
  sample_frac()

glimpse(sample_frac(azl))
```

### Missing

The _vast_ majority of entries are missing the `ppb_name`, as only _current_  Principal names are
listed in the `ppb` data frame.

```{r count_ppb_year}
count(ppb, rep_year)
```

However, the `lob` and `ref` data frames contain lobbyists and relationships dating back to
`r format(min(lob_reg$started, na.rm = T), "%b %d, %Y")`. For all those lobbyists and relationships
without corresponding names in `ppb`, rows are created with missing `ppb_*` values.

```{r glimpse_na}
glimpse_fun(azl, count_na)
```

```{r flag_na}
azl <- azl %>% flag_na(lob_lastname, ppb_name)
noquote(comma(sum(azl$na_flag)))
noquote(percent(mean(azl$na_flag)))
```

### Duplicates

```{r flag_dupes}
azl <- flag_dupes(azl, everything())
sum(azl$dupe_flag)
```

### Categorical

```{r glimpse_distinct}
glimpse_fun(azl, n_distinct)
```

## Wrangle

### Address

```{r address_normal}
packageVersion("tidyr")
azl <- azl %>% 
  # combine street addr
  unite(
    col = lob_addr_full,
    starts_with("lob_addr"),
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  # normalize combined addr
  mutate(
    lob_addr_norm = normal_address(
      address = lob_addr_full,
      add_abbs = usps_street,
      na_rep = TRUE
    )
  ) %>% 
  select(-lob_addr_full)
```

```{r address_view}
select(azl, starts_with("lob_addr")) %>% distinct() %>% sample_frac()
```

### ZIP

```{r zip_normal}
azl <- azl %>% 
  mutate(
    lob_zip_norm = normal_zip(
      zip = lob_zip,
      na_rep = TRUE
    )
  )
```

```{r zip_progress}
progress_table(
  azl$lob_zip,
  azl$lob_zip_norm,
  compare = valid_zip
)
```

### State

```{r state_normal}
azl <- azl %>% 
  mutate(
    lob_state_norm = normal_state(
      state = lob_state,
      abbreviate = TRUE,
      na_rep = TRUE,
      valid = valid_state
    )
  )
```

```{r state_progress}
progress_table(
  azl$lob_state,
  azl$lob_state_norm,
  compare = valid_state
)
```

### City

```{r normal_city}
azl <- azl %>% 
  mutate(
    lob_city_norm = normal_city(
      city = lob_city, 
      geo_abbs = usps_city,
      st_abbs = c("AZ", "DC", "ARIZONA"),
      na = c(invalid_city, ""),
      na_rep = TRUE
    )
  )
```

```{r swap_city}
azl <- azl %>% 
  left_join(
    y = zipcodes,
    by = c(
      "lob_state_norm" = "state",
      "lob_zip_norm" = "zip"
    )
  ) %>% 
  rename(lob_city_match = city) %>% 
  mutate(
    lob_match_abb = is_abbrev(lob_city_norm, lob_city_match),
    lob_match_dist = str_dist(lob_city_norm, lob_city_match),
    lob_city_swap = if_else(
      condition = lob_match_abb | lob_match_dist == 1,
      true = lob_city_match,
      false = lob_city_norm
    )
  )
```

```{r}
azl %>%
  filter(lob_city_swap %out% valid_city) %>%
  count(lob_city_swap, lob_city_match, lob_state_norm, sort = TRUE) %>% 
  drop_na() %>% 
  print(n = Inf)
```

```{r}
many_city <- c(
  valid_city,
  extra_city,
  "ORO VALLEY",
  "SUN LAKES",
  "PINETOP LAKESIDE",
  "CORAL GABLES"
)
```

```{r city_progress}
progress_table(
  azl$lob_city,
  azl$lob_city_norm,
  compare = many_city
)
```

## Conclude

1. There are `r nrow(azl)` records in the database.
1. There are `r sum(azl$dupe_flag)` duplicate records in the database.
1. The range and distribution of `amount` and `date` seem reasonable.
1. There are `r sum(azl$na_flag)` records missing either the lobbyist or principal name.
1. Consistency in goegraphic data has been improved with `campfin::normal_*()`.
1. The 5-digit `lob_zip_norm` variable has been created with `campfin::normal_zip()`.
1. The 4-digit `rep_year` was taken from the `ppb` data frame.

## Export

```{r create_proc_dir}
proc_dir <- here("az", "lobbying", "data", "processed")
dir_create(proc_dir)
```

```{r write_clean}
azl %>% 
  select(
    -lob_city_norm,
    -lob_city_match,
    -lob_match_abb,
    -lob_match_dist
  ) %>%
  rename(
    lob_addr_clean = lob_addr_norm,
    lob_zip_clean = lob_zip_norm,
    lob_state_clean = lob_state_norm,
    lob_city_clean = lob_city_swap
  ) %>% 
  write_csv(
    path = glue("{proc_dir}/az_type_clean.csv"),
    na = ""
  )
```

