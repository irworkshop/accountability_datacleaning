---
title: "Ohio Lobbyists"
author: "Kiernan Nicholls"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
fs::dir_create(here::here("oh", "lobbying", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This package contains
functions custom made to help facilitate the processing of campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load(
  stringdist, # levenshtein value
  RSelenium, # remote browser
  tidyverse, # data manipulation
  lubridate, # datetime strings
  magrittr, # pipe opperators
  janitor, # dataframe clean
  refinr, # cluster and merge
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  glue, # combine strings
  httr, # query the web
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here, collapse=TRUE}
# where does this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Data

Data is obtained from the [Ohio Legislative Inspector General][olig] (OLIG) Joint Legislative
Ethics Committee (JLEC)

> JLEC provides access to the database of all currently registered legislative agents, executive
agency and retirement system lobbyists, and their employers. If you want to search the database for
a specific agent or employer, this can be done in the website's Search For Lobbying Agents and
Employers feature. Alternatively, a complete list of all currently registered Agents and a separate
list of all Employers have been created and are updated daily. Please note, the lobbying lists
include both private and public sector employees.

[olig]: http://www.jlec-olig.state.oh.us/

## Import

### GET

The file can be downloaded directly from the [OLIG-JLEC website][raw] using an `httr::GET()`
request.

[raw]: https://www2.jlec-olig.state.oh.us/olac/Reports/AgentEmployerList.aspx

```{r}
raw_dir <- here("oh", "lobbying", "data", "raw")
dir_create(raw_dir)
```

```{r download_raw}
raw_url <- "https://www2.jlec-olig.state.oh.us/olac/Reports/agentList.aspx"
ohlr <- content(GET(raw_url)) %>% clean_names("snake")
```

## Explore

```{r glimpse}
head(ohlr)
tail(ohlr)
glimpse(sample_frac(ohlr))
```

### Missing

There are no records missing important information.

```{r glimpse_na}
glimpse_fun(ohlr, count_na)
```

```{r flag_na}
ohlr <- flag_na(ohlr, last_name, employer_name, zipcode)
if (sum(ohlr$na_flag) == 0) {
  ohlr <- select(ohlr, -na_flag)
}
```

### Duplicates

```{r flag_dupes}
ohlr <- flag_dupes(ohlr, everything())
if (sum(ohlr$dupe_flag) == 0) {
  ohlr <- select(ohlr, -dupe_flag)
}
```

## Wrangle

### Address

```{r address_normal}
packageVersion("tidyr")
ohlr <- ohlr %>% 
  # combine street addr
  unite(
    col = address_full,
    starts_with("address"),
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  # normalize combined addr
  mutate(
    address_norm = normal_address(
      address = address_full,
      abbs = usps_street,
      na_rep = TRUE
    )
  ) %>% 
  select(-address_full)
```

```{r address_view}
ohlr %>% 
  select(starts_with("address")) %>% 
  distinct() %>% 
  sample_frac()
```

### ZIP

```{r normal_zip}
ohlr <- ohlr %>% 
  mutate(
    zip_norm = normal_zip(
      zip = zipcode,
      na_rep = TRUE
    )
  )
```

```{r zip_progress, collapse=TRUE}
progress_table(
  ohlr$zipcode,
  ohlr$zip_norm,
  compare = valid_zip
)
```

### State

```{r state_normal}
ohlr <- ohlr %>% 
  mutate(
    state_norm = normal_state(
      state = state,
      abbreviate = TRUE,
      na_rep = TRUE,
      valid = NULL
    )
  )
```

```{r state_progress, collapse=TRUE}
progress_table(
  ohlr$state,
  ohlr$state_norm,
  compare = valid_state
)
```

### Citye

```{r city_normal}
ohlr <- ohlr %>% 
  mutate(
    city_norm = normal_city(
      city = city, 
      abbs = usps_city,
      states = c("OH", "DC", "OHIO"),
      na = invalid_city,
      na_rep = TRUE
    )
  )
```

```{r city_swap}
ohlr <- ohlr %>%
  rename(city_raw = city) %>% 
  left_join(
    y = zipcodes,
    by = c(
      "state_norm" = "state",
      "zip_norm" = "zip"
    )
  ) %>% 
  rename(city_match = city) %>% 
  mutate(
    match_dist = stringdist(city_norm, city_match),
    match_abb = is_abbrev(city_norm, city_match),
    city_swap = if_else(
      condition = match_abb | match_dist == 1,
      true = city_match,
      false = city_norm
    )
  )
```

```{r city_progress, collapse=TRUE}
progress_table(
  str_to_upper(ohlr$city_raw),
  ohlr$city_norm,
  ohlr$city_swap,
  compare = valid_city
)
```

```{r city_count}
ohlr %>% 
  filter(city_swap %out% valid_city) %>% 
  count(state_norm, city_swap, city_match, sort = TRUE)
```

### Year

```{r year_add}
ohlr <- mutate(ohlr, year = year(today()))
```

## Conclude

1. There are `r comma(nrow(ohlr))` records in the database.
1. There are no duplicate records in the database.
1. There are no records missing any pertinent information.
1. Consistency in goegraphic data has been improved with `campfin::normal_*()`.
1. The 5-digit `zip_norm` variable has been created with `campfin::normal_zip()`.
1. There is no date listed in the database. The current `year` was added.

## Export

```{r create_proc_dir}
proc_dir <- here("oh", "lobbying", "data", "processed")
dir_create(proc_dir)
```

```{r write_clean}
ohlr %>% 
  select(
    -city_match,
    -match_abb,
    -match_dist
  ) %>% 
  write_csv(
    path = glue("{proc_dir}/oh_lobby_reg.csv"),
    na = ""
  )
```

